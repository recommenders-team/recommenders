{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Autoencoder Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: linux\n",
      "Python:  3.6.7 | packaged by conda-forge | (default, Nov 21 2018, 03:09:43) \n",
      "[GCC 7.3.0]\n",
      "PyTorch: 1.0.0\n",
      "Number of CPU processors: 6\n",
      "Number of GPUs: 1\n",
      "CUDA Version 9.2.148\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "from reco_utils.common.gpu_utils import get_number_gpus, get_cuda_version\n",
    "from reco_utils.common.general_utils import get_number_processors, invert_dictionary\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_chrono_split\n",
    "from reco_utils.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var,\n",
    "                                                     map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k)\n",
    "from reco_utils.recommender.deep_autoencoder.autoencoder import AutoEncoder\n",
    "from reco_utils.recommender.deep_autoencoder.data import UserItemRecDataProvider\n",
    "from reco_utils.recommender.deep_autoencoder.utils import add_gpu, init_optimizer, MSEloss\n",
    "\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "print(\"OS:\", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Number of CPU processors:\", get_number_processors())\n",
    "print(\"Number of GPUs:\", get_number_gpus())\n",
    "print(get_cuda_version())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"ratings_train.csv\"\n",
    "valid_path = \"ratings_valid.csv\"\n",
    "test_path = \"ratings_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7e70acf30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params = {'batch_size': 128,\n",
    "                'major': 'users',  # major position is the first column id of input data\n",
    "                'itemIdInd': 1,  # the second index is the items\n",
    "                'userIdInd': 0,  # the first index is the users/customers\n",
    "                'delimiter': ',',\n",
    "                'header': True,\n",
    "                \"src_file\": train_path\n",
    "                }\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_layer = UserItemRecDataProvider(params=data_params)\n",
    "#dir(data_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   0,    0,    0,  ...,  127,  127,  127],\n",
      "                       [ 424,   54, 2049,  ..., 1430, 1439, 2230]]),\n",
      "       values=tensor([5., 3., 3.,  ..., 5., 5., 5.]),\n",
      "       size=(128, 6375), nnz=9835, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "for i, mb in enumerate(data_layer.iterate_one_epoch()):\n",
    "    print(mb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_params = copy.deepcopy(data_params)\n",
    "eval_params['src_file'] = valid_path\n",
    "validation_layer = UserItemRecDataProvider(\n",
    "    params=eval_params,\n",
    "    user_id_map=data_layer.user_id_map,\n",
    "    item_id_map=data_layer.item_id_map)\n",
    "validation_layer.src_data = data_layer.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../reco_utils/recommender/deep_autoencoder/autoencoder.py:46: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n",
      "../../reco_utils/recommender/deep_autoencoder/autoencoder.py:61: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [1024, 512, 512, 128]\n",
    "model = AutoEncoder(\n",
    "    layer_sizes=[data_layer.vector_dim] + hidden_layers,\n",
    "    nl_type=\"selu\",\n",
    "    is_constrained=False,\n",
    "    dp_drop_prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = add_gpu(model, \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler = init_optimizer(model,\n",
    "                       optimization_method=\"momentum\",\n",
    "                       lr=0.005,\n",
    "                       wd=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "cuda_availability = True\n",
    "def train_loop(rencoder, optimizer, scheduler=None):    \n",
    "    \"\"\"\n",
    "    Internal train loop\n",
    "    \"\"\"\n",
    "    t_loss = 0.0\n",
    "    t_loss_denom = 0.0\n",
    "    global_step = 0\n",
    "    best_loss = sys.maxsize\n",
    "    best_epoch = 0\n",
    "    epoch = 0\n",
    "    losing_patience = 0\n",
    "\n",
    "    # Params\n",
    "    noise_prob = 0.0\n",
    "    num_epochs = 20\n",
    "    aug_step = 1\n",
    "\n",
    "\n",
    "    if noise_prob > 0.0:\n",
    "        dp = nn.Dropout(p=noise_prob)\n",
    "\n",
    "    # Train until finish epochs or early stoping fires\n",
    "    while epoch < num_epochs and losing_patience < 10:\n",
    "        print('Doing epoch {} of {}'.format(epoch, num_epochs))\n",
    "        rencoder.train()\n",
    "        total_epoch_loss = 0.0\n",
    "        denom = 0.0\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        for i, mb in enumerate(data_layer.iterate_one_epoch()):\n",
    "            inputs = Variable(mb.cuda().to_dense()) if cuda_availability else Variable(mb.to_dense())\n",
    "            optimizer.zero_grad()\n",
    "            loss, outputs = _backprop(rencoder, inputs, optimizer)\n",
    "            global_step += 1\n",
    "            t_loss += loss.data.item()#loss.data[0]\n",
    "            t_loss_denom += 1\n",
    "            total_epoch_loss += loss.data.item()#loss.data[0]\n",
    "            denom += 1\n",
    "\n",
    "            if aug_step > 0:\n",
    "                # Magic data augmentation trick happen here\n",
    "                for t in range(aug_step):\n",
    "                    inputs = Variable(outputs.data)\n",
    "                    if noise_prob > 0.0:\n",
    "                        inputs = dp(inputs)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss, outputs = _backprop(\n",
    "                        rencoder, inputs, optimizer)\n",
    "\n",
    "        # Track model with lowest loss\n",
    "        epoch_loss = sqrt(total_epoch_loss/denom)\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, epoch_loss))\n",
    "        if True:# self.params['use_validation']:\n",
    "            epoch_loss = _evaluate_on_validation_set(rencoder)\n",
    "            print(\"Epoch {} - Validation loss: {}\".format(epoch,\n",
    "                                                              epoch_loss))\n",
    "        if epoch_loss < best_loss:\n",
    "            losing_patience = 0\n",
    "            best_loss = epoch_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(rencoder.state_dict())\n",
    "        else:\n",
    "            # early stoping\n",
    "            losing_patience += 1\n",
    "        epoch += 1\n",
    "\n",
    "    # Save final model\n",
    "    print(\"Best loss {} in epoch {}\".format(best_loss, best_epoch))\n",
    "    #self._save_model(best_model_wts, best_epoch)\n",
    "    #rencoder.load_state_dict(best_model_wts)\n",
    "\n",
    "def _backprop(rencoder, inputs, optimizer):\n",
    "    outputs = rencoder(inputs)\n",
    "    loss, num_ratings = MSEloss(outputs, inputs)\n",
    "    loss = loss / num_ratings\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, outputs\n",
    "\n",
    "def _evaluate_on_validation_set(rencoder):\n",
    "    rencoder.eval()\n",
    "    denom = 0.0\n",
    "    total_epoch_loss = 0.0\n",
    "    for target_mb, user_profile in validation_layer.iterate_one_epoch_eval():\n",
    "        inputs = Variable(user_profile.cuda().to_dense()) if cuda_availability else Variable(user_profile.to_dense())\n",
    "        targets = Variable(target_mb.cuda().to_dense()) if cuda_availability else Variable(target_mb.to_dense())\n",
    "        outputs = rencoder(inputs)\n",
    "        loss, num_ratings = MSEloss(outputs, targets)\n",
    "        total_epoch_loss += loss.data.item()#loss.data[0]\n",
    "        denom += num_ratings.data.item()#num_ratings.data[0]\n",
    "    return sqrt(total_epoch_loss / denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing epoch 0 of 20\n",
      "Epoch 0 - Training loss: 0.8397684036877522\n",
      "Epoch 0 - Validation loss: 1.0088240287902315\n",
      "Doing epoch 1 of 20\n",
      "Epoch 1 - Training loss: 0.8367286859629405\n",
      "Epoch 1 - Validation loss: 1.0082671629657438\n",
      "Doing epoch 2 of 20\n",
      "Epoch 2 - Training loss: 0.8378885122419276\n",
      "Epoch 2 - Validation loss: 1.007014279433431\n",
      "Doing epoch 3 of 20\n",
      "Epoch 3 - Training loss: 0.8360690931328426\n",
      "Epoch 3 - Validation loss: 1.005681530466913\n",
      "Doing epoch 4 of 20\n",
      "Epoch 4 - Training loss: 0.8298117032809726\n",
      "Epoch 4 - Validation loss: 1.0047572805108538\n",
      "Doing epoch 5 of 20\n",
      "Epoch 5 - Training loss: 0.828885582064895\n",
      "Epoch 5 - Validation loss: 1.0038280099692707\n",
      "Doing epoch 6 of 20\n",
      "Epoch 6 - Training loss: 0.8288188187116898\n",
      "Epoch 6 - Validation loss: 1.0027213862829305\n",
      "Doing epoch 7 of 20\n",
      "Epoch 7 - Training loss: 0.825830375487737\n",
      "Epoch 7 - Validation loss: 1.001512954053215\n",
      "Doing epoch 8 of 20\n",
      "Epoch 8 - Training loss: 0.8246885506528209\n",
      "Epoch 8 - Validation loss: 1.000410581692314\n",
      "Doing epoch 9 of 20\n",
      "Epoch 9 - Training loss: 0.8189405175943654\n",
      "Epoch 9 - Validation loss: 0.9999826142435578\n",
      "Doing epoch 10 of 20\n",
      "Epoch 10 - Training loss: 0.8185086644459183\n",
      "Epoch 10 - Validation loss: 0.9994990971470336\n",
      "Doing epoch 11 of 20\n",
      "Epoch 11 - Training loss: 0.8238109357115891\n",
      "Epoch 11 - Validation loss: 0.9989202198242709\n",
      "Doing epoch 12 of 20\n",
      "Epoch 12 - Training loss: 0.8260014856546818\n",
      "Epoch 12 - Validation loss: 0.9987298251024701\n",
      "Doing epoch 13 of 20\n",
      "Epoch 13 - Training loss: 0.8209925711710367\n",
      "Epoch 13 - Validation loss: 0.9982196218755716\n",
      "Doing epoch 14 of 20\n",
      "Epoch 14 - Training loss: 0.8151333609685844\n",
      "Epoch 14 - Validation loss: 0.9975937166983538\n",
      "Doing epoch 15 of 20\n",
      "Epoch 15 - Training loss: 0.8172146094294878\n",
      "Epoch 15 - Validation loss: 0.9968625121431043\n",
      "Doing epoch 16 of 20\n",
      "Epoch 16 - Training loss: 0.81629582438571\n",
      "Epoch 16 - Validation loss: 0.9964142042849181\n",
      "Doing epoch 17 of 20\n",
      "Epoch 17 - Training loss: 0.8131369734871394\n",
      "Epoch 17 - Validation loss: 0.9960070993605609\n",
      "Doing epoch 18 of 20\n",
      "Epoch 18 - Training loss: 0.8133916950262393\n",
      "Epoch 18 - Validation loss: 0.9954787681757146\n",
      "Doing epoch 19 of 20\n",
      "Epoch 19 - Training loss: 0.8161025582148054\n",
      "Epoch 19 - Validation loss: 0.9950957034046919\n",
      "Best loss 0.9950957034046919 in epoch 19\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>858</td>\n",
       "      <td>4.007101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6077</td>\n",
       "      <td>4.002754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>876</td>\n",
       "      <td>3.978678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>98491</td>\n",
       "      <td>3.950896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6461</td>\n",
       "      <td>3.812881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  itemID    rating\n",
       "0           1     858  4.007101\n",
       "1           1    6077  4.002754\n",
       "2           1     876  3.978678\n",
       "3           1   98491  3.950896\n",
       "4           1    6461  3.812881"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_k_items(model, data_layer, k=10):\n",
    "    \"\"\"\n",
    "    Predict function. It returns the top k rated items for each user.\n",
    "    These items have not been seen by the user yet.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Inverse mapping from internal user-item representation to input\n",
    "    # data representation\n",
    "    inv_user_id_map = invert_dictionary(data_layer.user_id_map)\n",
    "    inv_item_id_map = invert_dictionary(data_layer.item_id_map)\n",
    "\n",
    "    # Initialize result array\n",
    "    n_users = len(data_layer.user_id_map.keys())\n",
    "    results = np.zeros((n_users*k, 3))\n",
    "    for i, (mb, major_indices) in enumerate(\n",
    "            data_layer.iterate_one_epoch(shuffle_data=False)):\n",
    "        # Given a user profile compute the ratings of all items\n",
    "        inputs = Variable(mb.cuda().to_dense()) if cuda_availability else Variable(mb.to_dense())\n",
    "        outputs = model(inputs).cpu().data.numpy()\n",
    "\n",
    "        # Get the major_key of the origial input data (in this current\n",
    "        # implementation: customerID)\n",
    "        major_key = [inv_user_id_map[k] for k in major_indices]\n",
    "\n",
    "        # Select non viewed items\n",
    "        non_viewed_items = mb.to_dense().numpy() == 0\n",
    "        non_viewed_outputs = non_viewed_items*outputs\n",
    "\n",
    "        # Sort ratings of non viwed items and take top k\n",
    "        sorted_indices = np.fliplr(np.argsort(non_viewed_outputs, axis=1))[:, :k]\n",
    "\n",
    "        # Return a batch of top items with higher ratings that the user\n",
    "        # has not seen yet\n",
    "        batch_size = outputs.shape[0]  # size of current batch\n",
    "        results_internal = np.zeros((batch_size*k, 3))\n",
    "        for b in range(batch_size):\n",
    "            customer_id_batch = [major_key[b]]*k\n",
    "            item_id_batch = [inv_item_id_map[i]\n",
    "                             for i in sorted_indices[b, :]]\n",
    "            outputs_batch = outputs[b, sorted_indices[b, :]]\n",
    "            result_batch = np.column_stack(\n",
    "                (customer_id_batch, item_id_batch, outputs_batch))\n",
    "            results_internal[b*k:(b+1)*k, :] = result_batch\n",
    "\n",
    "        # Append the batch to results vector\n",
    "        result_batch_size = results_internal.shape[0]\n",
    "        results[i*result_batch_size:(i+1) *\n",
    "                result_batch_size, :] = results_internal\n",
    "\n",
    "    rec_df = pd.DataFrame(\n",
    "        results, columns=['customerID', 'itemID', 'rating'])\n",
    "    rec_df[\"customerID\"] = rec_df['customerID'].astype(np.int64)\n",
    "    rec_df[\"itemID\"]= rec_df['itemID'].astype(np.int64)\n",
    "    return rec_df\n",
    "\n",
    "df_ranking = recommend_k_items(model, data_layer)\n",
    "df_ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.498287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>2.879097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>2.303481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>2.848810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>3.486091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  itemID    rating\n",
       "0           1    2193  2.498287\n",
       "1           1    2968  2.879097\n",
       "2           1    1405  2.303481\n",
       "3           1    2150  2.848810\n",
       "4           1    1172  3.486091"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params = copy.deepcopy(data_params)\n",
    "test_params['src_file'] = test_path\n",
    "test_data_layer = UserItemRecDataProvider(\n",
    "    params=test_params,\n",
    "    user_id_map=data_layer.user_id_map,\n",
    "    item_id_map=data_layer.item_id_map)\n",
    "test_data_layer.src_data = data_layer.data\n",
    "\n",
    "\n",
    "def predict_regression(model, eval_data_layer, cols = ['customerID','itemID','rating']):\n",
    "    \"\"\"\n",
    "    Predict function for regression. It returns the predictions only of the\n",
    "    items rated in the evaluation set.\n",
    "    :param return_targets: Whether or not return the targets\n",
    "    :return: A dataframe with customer, item, predicted rating (and\n",
    "    optionally, the target rating)\n",
    "    \"\"\"\n",
    "    model.eval()    \n",
    "\n",
    "#     # Generate evaluation layer\n",
    "#     test_path = self.dataset.get_local_filepath(dataset.TEST_TYPE)\n",
    "#     self.data_params['src_file'] = test_path\n",
    "#     eval_data_layer = UserItemRecDataProvider(\n",
    "#         params=self.data_params,\n",
    "#         user_id_map=self.train_data_layer.user_id_map,  # mappings provided\n",
    "#         item_id_map=self.train_data_layer.item_id_map)\n",
    "#     # Populate evaluation layer with user profile\n",
    "#     eval_data_layer.src_data = self.train_data_layer.data\n",
    "\n",
    "    # Generate inverse user-item mapping: mapping from internal\n",
    "    # representation to input data\n",
    "    inv_user_id_map = invert_dictionary(eval_data_layer.user_id_map)\n",
    "    inv_item_id_map = invert_dictionary(eval_data_layer.item_id_map)\n",
    "\n",
    "    # FIXME: optimize iterate_one_epoch_eval to yield data of batch_size.\n",
    "    # Check whether using batch_size>1 generates wrong results.\n",
    "    results = []\n",
    "    for i, ((targets, user_profile), major_ind) in enumerate(\n",
    "            eval_data_layer.iterate_one_epoch_eval(for_inf=True)):\n",
    "        # Given a user profile compute the ratings of all items\n",
    "        inputs = Variable(user_profile.cuda().to_dense()) if cuda_availability else Variable(user_profile.to_dense())\n",
    "        outputs = model(inputs).cpu().data.numpy()[0, :]\n",
    "\n",
    "        # Get the major_key of the origial input data (in this current\n",
    "        # implementation: customerID)\n",
    "        major_key = inv_user_id_map[major_ind]\n",
    "\n",
    "        # Get the evaluation targets, most elements are going to be zero.\n",
    "        # Also get the non zero indices in non_zero\n",
    "        targets_np = targets.to_dense().numpy()[0, :]\n",
    "        non_zeros = targets_np.nonzero()[0].tolist()\n",
    "\n",
    "        # Create a dataframe with the prediction selecting only the\n",
    "        # indexes of the items scored in the test set\n",
    "        for ind in non_zeros:\n",
    "            result = [major_key, inv_item_id_map[ind], outputs[ind]]\n",
    "            results.append(result)\n",
    "    test_pred = pd.DataFrame(results, columns=cols)\n",
    "\n",
    "    return test_pred\n",
    "\n",
    "df_rating = predict_regression(model, test_data_layer)\n",
    "df_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  itemID  rating\n",
       "0           1    1172     4.0\n",
       "1           1    1405     1.0\n",
       "2           1    2150     3.0\n",
       "3           1    2193     2.0\n",
       "4           1    2968     1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(test_path).drop([\"timeStamp\", \"binary_rating\"], axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t1.024445\n",
      "MAE:\t\t0.778484\n",
      "rsquared:\t0.047928\n",
      "exp var:\t0.051888\n",
      "----\n",
      "MAP:\t0.000418\n",
      "NDCG:\t0.002240\n",
      "Precision@K:\t0.002188\n",
      "Recall@K:\t0.002178\n"
     ]
    }
   ],
   "source": [
    "cols = {\"col_user\": \"customerID\",\n",
    "        \"col_item\": \"itemID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "        \"col_prediction\": \"rating\"}\n",
    "\n",
    "eval_rmse = rmse(test, df_rating,**cols)\n",
    "eval_mae = mae(test, df_rating,**cols)\n",
    "eval_rsquared = rsquared(test, df_rating,**cols)\n",
    "eval_exp_var = exp_var(test, df_rating,**cols)\n",
    "\n",
    "k = 10\n",
    "eval_map = map_at_k(test, df_ranking, **cols, k=k)\n",
    "eval_ndcg = ndcg_at_k(test, df_ranking,**cols, k=k)\n",
    "eval_precision = precision_at_k(test, df_ranking,**cols, k=k)\n",
    "eval_recall = recall_at_k(test, df_ranking,**cols, k=k)\n",
    "\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')\n",
    "\n",
    "print('----')\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_gpu)",
   "language": "python",
   "name": "reco_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
