{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning by using **Azure Machine Learning service** ([AML or AzureML](https://azure.microsoft.com/en-us/services/machine-learning-service/)).  \n",
    "\n",
    "Specifically, we utilize TensorFlow's higher level Estimator API to build [wide-and-deep model](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html) for a movie recommendation scenario. While doing that, we try to search optimal hyperparameters via [AML hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "* azureml -- You can skip this if you already know what values of hyperparameters you want to use\n",
    "\n",
    "\n",
    "For details about how to install and setup AML, see following materials:\n",
    "- [AML quickstart](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)\n",
    "- [Train a TensorFlow model](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-tensorflow)\n",
    "- [Hyperparameter tuning](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version: 1.0.2\n",
      "Tensorflow Version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.hyperdrive import *\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "\n",
    "print(\"Azure ML SDK Version:\", azureml.core.VERSION)\n",
    "print(\"Tensorflow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyperparameter Tuning via AML\n",
    "\n",
    "This section assumes you already created a **Azure ML workspace** and have a `./aml_config/config.json` file to load the workspace from this notebook. If not, please follow instructions in the [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started) to create a workspace and make a `./aml_config/config.json` file containing:\n",
    "```\n",
    "{\n",
    "    \"subscription_id\": \"your-subscription-id\",\n",
    "    \"resource_group\": \"your-resource-group\",\n",
    "    \"workspace_name\": \"your-workspace-name\"\n",
    "}\n",
    "```\n",
    "  \n",
    "From the following cells, we will\n",
    "1. Create a remote compute target (gpu-cluster) if it does not exist already,\n",
    "2. Mount data store and upload the training set, and\n",
    "3. Run a hyperparameter tuning experiment.\n",
    "\n",
    "First, let's connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\jumin\\git\\Recommenders\\notebooks\\02_model\\aml_config\\config.json\n",
      "Workspace name:  junmin-aml-workspace\n"
     ]
    }
   ],
   "source": [
    "# Connect to a workspace\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a remote compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2018-12-31T20:55:27.147000+00:00', 'creationTime': '2018-12-29T20:07:54.814212+00:00', 'currentNodeCount': 1, 'errors': None, 'modifiedTime': '2018-12-29T20:08:23.921123+00:00', 'nodeStateCounts': {'idleNodeCount': 1, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 1, 'vmPriority': 'LowPriority', 'vmSize': 'STANDARD_NC6'}\n",
      "gpu-cluster AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "CLUSTER_NAME = 'gpu-cluster'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n",
    "    print(\"Found existing compute target\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='STANDARD_NC6',\n",
    "        vm_priority='lowpriority',\n",
    "        min_nodes=1,\n",
    "        max_nodes=4\n",
    "    )\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(compute_target.status.serialize())\n",
    "\n",
    "# Check list of aml-computes\n",
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset\n",
    "1. Download data and train/test split\n",
    "2. Upload to storage\n",
    "\n",
    "Next, upload the training set to the data store. This example uses the workspace's default **blob storage**.\n",
    "  \n",
    "We also prepare a training script [wide_deep_training.py](../../reco_utils/aml/wide_deep_training.py) for the hyperparameter tuning, which will log our target metrics (e.g. [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)) to AML experiment so that we can track the metrics and optimize it via **hyperdrive**.\n",
    "\n",
    "```\n",
    "TODO - maybe attach a code snippet here for description\n",
    "1. logging part\n",
    "\n",
    "2. wide and deep model\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  MovieId  Rating  Timestamp\n",
       "0     196      242     3.0  881250949\n",
       "1     186      302     3.0  891717742\n",
       "2      22      377     1.0  878887116\n",
       "3     244       51     2.0  880606923\n",
       "4     166      346     1.0  886397596"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=['UserId','MovieId','Rating','Timestamp'],\n",
    "    # TODO For now, not using genres YET\n",
    "    load_genres=False\n",
    ")\n",
    "data.head()\n",
    "\n",
    "train_df, test_df = python_random_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_595956bc8be442fda5a5d6d5b52b1bb8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"./data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_train.pkl\"\n",
    "\n",
    "train_df.to_pickle(os.path.join(DATA_DIR, TRAIN_FILE_NAME))\n",
    "\n",
    "# Note, all the files under DATA_DIR will be uploaded\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(\n",
    "    src_dir=DATA_DIR,\n",
    "    target_path='data',\n",
    "    overwrite=True,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training script. All the script in the folder will be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./aml_scripts\\\\tf_utils.py'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_DIR = './aml_scripts'\n",
    "ENTRY_SCRIPT_NAME = 'wide_deep_training.py'\n",
    "\n",
    "os.makedirs(SCRIPT_DIR, exist_ok=True)\n",
    "shutil.copy('../../reco_utils/aml/wide_deep_training.py', SCRIPT_DIR)\n",
    "shutil.copy('../../reco_utils/common/tf_utils.py', SCRIPT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a search space for the hyperparameters. All the parameter values will be passed to the training script where they are parsed by `argparse`, e.g.:\n",
    "```\n",
    "TODO code snippet for argparse\n",
    "```\n",
    "    \n",
    "AML hyperdrive provides some very useful searching strategies including `RandomParameterSampling`, `GridParameterSampling`, and `BayesianParameterSampling`. Details about each approach are beyond the scope of this notebook and you can find them from [Azure doc](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters). Here, we use the random sampling for simplicity. \n",
    "\n",
    "> Note: Currently, this repo accepts either 'rmse' or 'mae' for `METRICS` as implemented in [tf_utils.py](../../reco_utils/common/tf_utils.py), but you can define any custom metrics and utilize it along with AML hyperdrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mlworkspace.azure.ai/portal/subscriptions/03909a66-bef8-4d52-8e9a-a346604e0902/resourceGroups/junmin-aml/providers/Microsoft.MachineLearningServices/workspaces/junmin-aml-workspace/experiments/movielens_100k_wide/runs/movielens_100k_wide_1546313676294\n"
     ]
    }
   ],
   "source": [
    "EXP_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_wide_deep\"\n",
    "METRICS = 'rmse'\n",
    "\n",
    "script_params = {\n",
    "    '--datastore': ds.as_mount(),\n",
    "    '--train-set-path': \"data/\" + TRAIN_FILE_NAME,\n",
    "    '--user-col': 'UserId',\n",
    "    '--item-col': 'MovieId',\n",
    "    '--rating-col': 'Rating',\n",
    "    '--timestamp-col': 'Timestamp',\n",
    "#     '--item-feat-col': 'Genres',\n",
    "#     '--item_feat-num': 11? check this\n",
    "    # We fixed the batch size and epochs instead of search them\n",
    "    '--batch-size': 64,\n",
    "    '--epochs': 50,\n",
    "    '--eval-metrics': METRICS,\n",
    "}\n",
    "\n",
    "hyper_params = {\n",
    "    '--model-type': choice('wide', 'deep', 'wide-deep'),\n",
    "    # Wide model hyperparameters\n",
    "    '--linear-optimizer': choice('Ftrl', 'SGD'),\n",
    "    '--linear-optimizer-lr': loguniform(-7, -2),\n",
    "    # Deep model hyperparameters\n",
    "    '--dnn-optimizer': choice('Adagrad', 'Adam'),\n",
    "    '--dnn-optimizer-lr': loguniform(-7, -2),\n",
    "    '--hidden-units': choice(\n",
    "        [256, 256, 256, 128],\n",
    "        [256, 128],\n",
    "        [256, 64, 64, 256],\n",
    "        [1024, 128, 32]\n",
    "    ),\n",
    "    '--user-embedding-dim': choice(4, 8, 16),\n",
    "    '--item-embedding-dim': choice(8, 32, 128),\n",
    "    '--dnn-dropout': uniform(0.0, 0.5),\n",
    "    '--dnn-batch-norm': choice(True, False),\n",
    "}\n",
    "\n",
    "ps = RandomParameterSampling(hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `azureml.train.dnn.TensorFlow`, a custom AML `Estimator` class which utilizes a preset docker image in the cluster (see more information from [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-tensorflow)).\n",
    "\n",
    "Once you submit the experiment, you can see the progress from the notebook by using `azureml.widgets.RunDetails`. You can directly check the details from the Azure portal as well. To get the link, run `run.get_portal_url()`.\n",
    "\n",
    "> Since we will do hyperparameter tuning, we create a `HyperDriveRunConfig` and pass it to the experiment object. If you already know what hyperparameters to use and still want to utilize AML for other purposes (e.g. model management), you can set the hyperparameter values directly to `script_params` and run the experiment, `run = exp.submit(est)`, instead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = TensorFlow(\n",
    "    source_directory=SCRIPT_DIR,\n",
    "    entry_script=TRAINING_SCRIPT_NAME,\n",
    "    script_params=script_params,\n",
    "    compute_target=compute_target,\n",
    "    use_gpu=True,\n",
    "    pip_packages=['pandas']\n",
    ")\n",
    "\n",
    "# early termnination policy\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "hd_config = HyperDriveRunConfig(\n",
    "    estimator=est, \n",
    "    hyperparameter_sampling=ps,\n",
    "    policy=policy,  \n",
    "    primary_metric_name=METRICS,\n",
    "    primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "    max_total_runs=20,\n",
    "    max_concurrent_runs=4\n",
    ")\n",
    "\n",
    "# Create an experiment to track the runs in the workspace\n",
    "exp = Experiment(workspace=ws, name=EXP_NAME)\n",
    "run = exp.submit(config=hd_config)\n",
    "\n",
    "print(run.get_portal_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621e93e9e9bd450d9fa6e1bd8ef6815e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSEâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: movielens_100k_wide_1546313676294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-31 22:50:18,461 WARNING Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000228590C28D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)': /history/v1.0/subscriptions/03909a66-bef8-4d52-8e9a-a346604e0902/resourceGroups/junmin-aml/providers/Microsoft.MachineLearningServices/workspaces/junmin-aml-workspace/experiments/movielens_100k_wide/runs/movielens_100k_wide_1546313676294/details\n",
      "2018-12-31 23:35:36,823 WARNING Retrying (Retry(total=1, connect=1, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000022858EAAB38>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)': /history/v1.0/subscriptions/03909a66-bef8-4d52-8e9a-a346604e0902/resourceGroups/junmin-aml/providers/Microsoft.MachineLearningServices/workspaces/junmin-aml-workspace/experiments/movielens_100k_wide/runs/movielens_100k_wide_1546313676294/details\n",
      "2018-12-31 23:35:40,102 WARNING Retrying (Retry(total=0, connect=0, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000228590BD6D8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',)': /history/v1.0/subscriptions/03909a66-bef8-4d52-8e9a-a346604e0902/resourceGroups/junmin-aml/providers/Microsoft.MachineLearningServices/workspaces/junmin-aml-workspace/experiments/movielens_100k_wide/runs/movielens_100k_wide_1546313676294/details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: movielens_100k_wide_1546313676294\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'movielens_100k_wide_1546313676294',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'endTimeUtc': '2019-01-01T03:55:10.000Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"rmse\", \"goal\": \"minimize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://junminamlworks3904856782.blob.core.windows.net/azureml/ExperimentRun/movielens_100k_wide_1546313676294/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=0c2teKLgCV6v94pWHwGvoYSYOCt9gQiJNoFDaw0s54E%3D&st=2019-01-01T04%3A25%3A42Z&se=2019-01-01T12%3A35%3A42Z&sp=r'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop, run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "To load a registered model in the future,\n",
    "```\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model(ws, 'model_name')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecated, use RunHistoryFacade.assets instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'outputs/model/1546314741/saved_model.pb', 'outputs/model/1546314741/variables/variables.data-00000-of-00002', 'outputs/model/1546314741/variables/variables.data-00001-of-00002', 'outputs/model/1546314741/variables/variables.index', 'driver_log', 'azureml-logs/azureml.log', 'azureml-logs/55_batchai_execution.txt']\n",
      "movielens_100k_wide movielens_100k_wide:1 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'       \\n        \\n\\n\\ntf.reset_default_graph()\\n\\nsaver = tf.train.import_meta_graph(\"./model/mnist-tf.model.meta\")\\ngraph = tf.get_default_graph()\\n\\nfor op in graph.get_operations():\\n    if op.name.startswith(\\'network\\'):\\n        print(op.name)\\n\\n# input tensor. this is an array of 784 elements, each representing the intensity of a pixel in the digit image.\\nX = tf.get_default_graph().get_tensor_by_name(\"network/X:0\")\\n# output tensor. this is an array of 10 elements, each representing the probability of predicted value of the digit.\\noutput = tf.get_default_graph().get_tensor_by_name(\"network/output/MatMul:0\")\\n\\nwith tf.Session() as sess:\\n    saver.restore(sess, \\'./model/mnist-tf.model\\')\\n    k = output.eval(feed_dict={X : X_test})\\n# get the prediction, which is the index of the element that has the largest probability value.\\ny_hat = np.argmax(k, axis=1)\\n\\n# print the first 30 labels and predictions\\nprint(\\'labels:  \\t\\', y_test[:30])\\nprint(\\'predictions:\\t\\', y_hat[:30])\\n\\n\\n\\n\\n\\n# TODO...\\nmodel_root = Model.get_model_path(\\'tf-dnn-mnist\\')\\n    saver = tf.train.import_meta_graph(os.path.join(model_root, \\'mnist-tf.model.meta\\'))\\n    X = tf.get_default_graph().get_tensor_by_name(\"network/X:0\")\\n    output = tf.get_default_graph().get_tensor_by_name(\"network/output/MatMul:0\")\\n    \\n    sess = tf.Session()\\n    saver.restore(sess, os.path.join(model_root, \\'mnist-tf.model\\'))\\n\\ndef run(raw_data):\\n    data = np.array(json.loads(raw_data)[\\'data\\'])\\n    # make prediction\\n    out = output.eval(session=sess, feed_dict={X: data})\\n    y_hat = np.argmax(out, axis=1)\\n    return y_hat.tolist()\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = './model'\n",
    "\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "# Check model files uploaded during the run\n",
    "print(best_run.get_file_names())\n",
    "\n",
    "# Register the model in the workspace so that can later query, examine, and deploy this model.\n",
    "# TODO check model path...\n",
    "model = best_run.register_model(model_name=MODEL_NAME, model_path='./outputs/model')\n",
    "print(model.name, model.id, model.version)\n",
    "\n",
    "# Download the model to local. (alternatively, run.download_file(name=f, output_file_path=output_file_path))\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "model.download(target_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"       \n",
    "        \n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./model/mnist-tf.model.meta\")\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "for op in graph.get_operations():\n",
    "    if op.name.startswith('network'):\n",
    "        print(op.name)\n",
    "\n",
    "# input tensor. this is an array of 784 elements, each representing the intensity of a pixel in the digit image.\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"network/X:0\")\n",
    "# output tensor. this is an array of 10 elements, each representing the probability of predicted value of the digit.\n",
    "output = tf.get_default_graph().get_tensor_by_name(\"network/output/MatMul:0\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/mnist-tf.model')\n",
    "    k = output.eval(feed_dict={X : X_test})\n",
    "# get the prediction, which is the index of the element that has the largest probability value.\n",
    "y_hat = np.argmax(k, axis=1)\n",
    "\n",
    "# print the first 30 labels and predictions\n",
    "print('labels:  \\t', y_test[:30])\n",
    "print('predictions:\\t', y_hat[:30])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO...\n",
    "model_root = Model.get_model_path('tf-dnn-mnist')\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_root, 'mnist-tf.model.meta'))\n",
    "    X = tf.get_default_graph().get_tensor_by_name(\"network/X:0\")\n",
    "    output = tf.get_default_graph().get_tensor_by_name(\"network/output/MatMul:0\")\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    saver.restore(sess, os.path.join(model_root, 'mnist-tf.model'))\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    out = output.eval(session=sess, feed_dict={X: data})\n",
    "    y_hat = np.argmax(out, axis=1)\n",
    "    return y_hat.tolist()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    rmse, mae, rsquared, exp_var,\n",
    "    map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    ")\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test.copy()\n",
    "y_test = X_test.pop('Rating')\n",
    "\n",
    "# test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "#     x=X_test,\n",
    "#     num_epochs=1,\n",
    "#     shuffle=False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model/1546314741\\variables\\variables\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Name: <unknown>, Key: UserId, Index: 0.  Data types don't match. Expected type: string, Actual type: float\n\t [[node ParseExample/ParseExample (defined at C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py:153)  = ParseExample[Ndense=0, Nsparse=2, Tdense=[], dense_shapes=[], sparse_types=[DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_example_tensor_0_0, ParseExample/ParseExample/names, ParseExample/ParseExample/sparse_keys_0, ParseExample/ParseExample/sparse_keys_1)]]\n\nCaused by op 'ParseExample/ParseExample', defined at:\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-9b8a7e6335f6>\", line 1, in <module>\n    model = tf.contrib.predictor.from_saved_model(MODEL_DIR+\"/model/1546314741\")\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 197, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 350, in load\n    **saver_kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 278, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1696, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3440, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3440, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3299, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Name: <unknown>, Key: UserId, Index: 0.  Data types don't match. Expected type: string, Actual type: float\n\t [[node ParseExample/ParseExample (defined at C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py:153)  = ParseExample[Ndense=0, Nsparse=2, Tdense=[], dense_shapes=[], sparse_types=[DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_example_tensor_0_0, ParseExample/ParseExample/names, ParseExample/ParseExample/sparse_keys_0, ParseExample/ParseExample/sparse_keys_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Name: <unknown>, Key: UserId, Index: 0.  Data types don't match. Expected type: string, Actual type: float\n\t [[{{node ParseExample/ParseExample}} = ParseExample[Ndense=0, Nsparse=2, Tdense=[], dense_shapes=[], sparse_types=[DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_example_tensor_0_0, ParseExample/ParseExample/names, ParseExample/ParseExample/sparse_keys_0, ParseExample/ParseExample/sparse_keys_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9b8a7e6335f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mexamples\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, input_dict)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Name: <unknown>, Key: UserId, Index: 0.  Data types don't match. Expected type: string, Actual type: float\n\t [[node ParseExample/ParseExample (defined at C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py:153)  = ParseExample[Ndense=0, Nsparse=2, Tdense=[], dense_shapes=[], sparse_types=[DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_example_tensor_0_0, ParseExample/ParseExample/names, ParseExample/ParseExample/sparse_keys_0, ParseExample/ParseExample/sparse_keys_1)]]\n\nCaused by op 'ParseExample/ParseExample', defined at:\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-9b8a7e6335f6>\", line 1, in <module>\n    model = tf.contrib.predictor.from_saved_model(MODEL_DIR+\"/model/1546314741\")\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 197, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 350, in load\n    **saver_kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 278, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1696, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 806, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 442, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 234, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3440, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3440, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3299, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Name: <unknown>, Key: UserId, Index: 0.  Data types don't match. Expected type: string, Actual type: float\n\t [[node ParseExample/ParseExample (defined at C:\\Users\\jumin\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\contrib\\predictor\\saved_model_predictor.py:153)  = ParseExample[Ndense=0, Nsparse=2, Tdense=[], dense_shapes=[], sparse_types=[DT_STRING, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_input_example_tensor_0_0, ParseExample/ParseExample/names, ParseExample/ParseExample/sparse_keys_0, ParseExample/ParseExample/sparse_keys_1)]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.contrib.predictor.from_saved_model(MODEL_DIR+\"/model/1546314741\")\n",
    "# model = tf.contrib.estimator.SavedModelEstimator(MODEL_DIR+\"/model/1546314741\")\n",
    "\n",
    "# Convert input data into serialized Example strings.\n",
    "examples = []\n",
    "for index, row in X_test.iterrows():\n",
    "    feature = {}\n",
    "    for col, value in row.iteritems():\n",
    "        feature[col] = tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature=feature\n",
    "        )\n",
    "    )\n",
    "    examples.append(example.SerializeToString())\n",
    "\n",
    "predictions = model({'inputs': examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jumin\\AppData\\Local\\Temp\\tmptw9dk7nt\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jumin\\\\AppData\\\\Local\\\\Temp\\\\tmptw9dk7nt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000228576F9EB8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Checking available modes for SavedModelEstimator.\n",
      "WARNING:tensorflow:train mode not found in SavedModel.\n",
      "WARNING:tensorflow:eval mode not found in SavedModel.\n",
      "INFO:tensorflow:Available modes for Estimator: ['infer']\n",
      "INFO:tensorflow:Could not find trained model in model_dir: C:\\Users\\jumin\\AppData\\Local\\Temp\\tmptw9dk7nt, running initialization to predict.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'yellow' has type str, but expected one of: bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-28b21d82af34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mpred_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         features, input_hooks = self._get_features_from_input_fn(\n\u001b[1;32m--> 575\u001b[1;33m             input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[0;32m    576\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m    577\u001b[0m             features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1048\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_features_from_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_input_fn_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features_in_predict_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1160\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-28b21d82af34>\u001b[0m in \u001b[0;36mpredict_input_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbytes_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'yellow'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'yellow' has type str, but expected one of: bytes"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# def predict_input_fn():\n",
    "#     example = tf.train.Example()\n",
    "#     example.features.feature['feature1'].bytes_list.value.extend(['yellow'])\n",
    "#     example.features.feature['feature2'].float_list.value.extend([1.])\n",
    "#     return {'inputs':tf.constant([example.SerializeToString()])}\n",
    "\n",
    "# If all modes were exported, you can immediately evaluate and predict, or\n",
    "# continue training. Otherwise only predict is available.\n",
    "# See https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/export_all_saved_models\n",
    "\n",
    "# eval_results = model.evaluate(input_fn=input_fn, steps=1)\n",
    "# print(eval_results)\n",
    "# model.train(input_fn=input_fn, steps=20)\n",
    "\n",
    "\n",
    "\n",
    "predictions = predict_fn(\n",
    "    {\"x\": [[6.4, 3.2, 4.5, 1.5],\n",
    "           [5.8, 3.1, 5.0, 1.7]]})\n",
    "print(predictions['scores'])\n",
    "\n",
    "\n",
    "\n",
    "pred_list = [p['predictions'][0] for p in list(model.predict(predict_input_fn))]\n",
    "predictions = test.copy()\n",
    "predictions['prediction']  = pd.Series(pred_list).values\n",
    "print(predictions.head())\n",
    "\n",
    "cols = {\n",
    "    'col_user': 'UserId',\n",
    "    'col_item': 'MovieId',\n",
    "    'col_rating': 'Rating',\n",
    "    'col_prediction': 'prediction'\n",
    "}\n",
    "\n",
    "predictions.drop('Rating', axis=1, inplace=True)\n",
    "\n",
    "eval_rmse = rmse(test, predictions, **cols)\n",
    "eval_mae = mae(test, predictions, **cols)\n",
    "eval_rsquared = rsquared(test, predictions, **cols)\n",
    "eval_exp_var = exp_var(test, predictions, **cols)\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')\n",
    "\n",
    "# Load the downloaded model and test\n",
    "# with tf.Session() as sess:\n",
    "#     tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], MODEL_DIR)\n",
    "\n",
    "# #     test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "# #         x=X_test,\n",
    "# #         y=y_test,\n",
    "# #         batch_size=BATCH_SIZE,\n",
    "# #         num_epochs=1,\n",
    "# #         shuffle=False\n",
    "# #     )\n",
    "    \n",
    "#     input_x_holder =sess.graph.get_operation_by_name(\"input_example_tensor\").outputs[0]\n",
    "# #check your dnn classifier txt pb to know which operation you should use.\n",
    "# predictions_holder = sess.graph.get_operation_by_name(\"dnn/binary_logistic_head/predictions/probabilities\").outputs[0]\n",
    "    \n",
    "#     predictor = tf.contrib.predictor.from_saved_model(MODEL_DIR)\n",
    "#         model_input = tf.train.Example(features=tf.train.Features( feature={\"words\": tf.train.Feature(int64_list=tf.train.Int64List(value=features_test_set)) })) \n",
    "#         model_input = model_input.SerializeToString()\n",
    "#         output_dict = predictor({\"predictor_inputs\":[model_input]})\n",
    "#         y_predicted = output_dict[\"pred_output_classes\"][0]\n",
    "#         output_dict['scores']\n",
    "\n",
    "#         input_tensor=tf.get_default_graph().get_tensor_by_name(\"input_tensors:0\")\n",
    "#         model_input=input_tensor.SerializeToString()        \n",
    "#         output_dict= predictor({\"inputs\":[model_input]})\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up resources\n",
    "ws.delete(delete_dependent_resources=True)\n",
    "\n",
    "# optionally, delete the Azure Managed Compute cluster\n",
    "compute_target.delete()\n",
    "\n",
    "# Clean-up temporal local-copy of script, model and data files\n",
    "shutil.rmtree(SCRIPT_DIR)\n",
    "shutil.rmtree(DATA_DIR)\n",
    "shutil.rmtree(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [Fine-tune natural language processing models using Azure Machine Learning service](https://azure.microsoft.com/en-us/blog/fine-tune-natural-language-processing-models-using-azure-machine-learning-service/)\n",
    "* [Training, hyperparameter tune, and deploy with TensorFlow](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
