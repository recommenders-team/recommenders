{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.<br>\n",
    "Licensed under the MIT License.</i>\n",
    "<br><br>\n",
    "# SVD Hyperparameter Tuning with Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to tune the hyperparameters of a matrix factorization algorithm by utilizing **Azure Machine Learning service** ([AzureML](https://azure.microsoft.com/en-us/services/machine-learning-service/)) in the context of movie recommendations. To use AzureML you will need an Azure subscription. We use the SVD algorithm from the Surprise library.\n",
    "\n",
    "We present the overall process of utilizing AzureML by demonstrating some key steps while avoiding too much detail. \n",
    "\n",
    "For more details about the **SVD** algorithm:\n",
    "* [Surprise SVD deep-dive notebook](../02_model/surprise_svd_deep_dive.ipynb)\n",
    "* [Original paper](http://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf)\n",
    "* [Surprise homepage](https://surprise.readthedocs.io/en/stable/)\n",
    "  \n",
    "Regarding **AzureML**, please refer to:\n",
    "* [Quickstart notebook](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)\n",
    "* [Hyperdrive](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "Surprise version: 1.0.6\n",
      "Azure ML SDK Version: 1.0.10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import os\n",
    "import surprise\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Surprise version: {}\".format(surprise.__version__))\n",
    "\n",
    "import azureml as aml\n",
    "import azureml.widgets\n",
    "import azureml.train.hyperdrive as hd\n",
    "\n",
    "print(\"Azure ML SDK Version:\", aml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to use azure cli credentials. This fall back to use azure cli credentials will be removed in the next release. \n",
      "Make sure your code doesn't require 'az login' to have happened before using azureml-sdk, except the case when you are specifying AzureCliAuthentication in azureml-sdk.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code DK8XYUTV3 to authenticate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/anargyri/notebooks/Recommenders/notebooks/04_model_select_and_optimize/aml_config/config.json\n",
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7f1a6ea84700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Connect to a workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWorkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUserErrorException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/azureml/core/workspace.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(path, auth)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found the config file in: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         return Workspace(subscription_id_from_config, resource_group_from_config, workspace_name_from_config,\n\u001b[0;32m--> 151\u001b[0;31m                          auth=auth)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/azureml/core/workspace.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, subscription_id, resource_group, workspace_name, auth, _location, _disable_service_check)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \"\"\"\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInteractiveLoginAuthentication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/azureml/core/authentication.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, force, tenant_id)\u001b[0m\n\u001b[1;32m    285\u001b[0m                     print(\"Performing interactive authentication. Please follow the instructions \"\n\u001b[1;32m    286\u001b[0m                           \"on the terminal.\")\n\u001b[0;32m--> 287\u001b[0;31m                     \u001b[0mperform_interactive_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtenant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtenant_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interactive authentication successfully completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/azureml/_base_sdk_common/common.py\u001b[0m in \u001b[0;36mperform_interactive_login\u001b[0;34m(username, password, service_principal, tenant, allow_no_subscriptions, identity, use_device_code, use_cert_sn_issuer)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0muse_device_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_device_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mallow_no_subscriptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_no_subscriptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             use_cert_sn_issuer=use_cert_sn_issuer)\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAdalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# try polish unfriendly server errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/azureml/_vendor/azure_cli_core/_profile.py\u001b[0m in \u001b[0;36mfind_subscriptions_on_login\u001b[0;34m(self, interactive, username, password, is_service_principal, tenant, use_device_code, allow_no_subscriptions, subscription_finder, use_cert_sn_issuer)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_device_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 subscriptions = subscription_finder.find_through_interactive_flow(\n\u001b[0;32m--> 236\u001b[0;31m                     tenant, self._ad_resource_uri)\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_service_principal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/azureml/_vendor/azure_cli_core/_profile.py\u001b[0m in \u001b[0;36mfind_through_interactive_flow\u001b[0;34m(self, tenant, resource)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_user_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_CLIENT_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mtoken_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_token_with_device_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_CLIENT_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_entry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_TOKEN_ENTRY_USER_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtenant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/adal/authentication_context.py\u001b[0m in \u001b[0;36macquire_token_with_device_code\u001b[0;34m(self, resource, user_code_info, client_id)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_code_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'correlation_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancel_request_to_get_token_with_device_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_code_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/adal/authentication_context.py\u001b[0m in \u001b[0;36m_acquire_token\u001b[0;34m(self, token_func, correlation_id)\u001b[0m\n\u001b[1;32m    126\u001b[0m             correlation_id or self.correlation_id, self._call_context.get('enable_pii', False))\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthority\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/adal/authentication_context.py\u001b[0m in \u001b[0;36mtoken_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_requests_with_user_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token_with_device_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_code_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/adal/token_request.py\u001b[0m in \u001b[0;36mget_token_with_device_code\u001b[0;34m(self, user_code_info)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_polling_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token_with_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moauth_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpires_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_token_into_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/reco_base/lib/python3.6/site-packages/adal/oauth2_client.py\u001b[0m in \u001b[0;36mget_token_with_polling\u001b[0;34m(self, oauth_parameters, refresh_internal, expires_in)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwire_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOAuth2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeviceCodeResponseParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'authorization_pending'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefresh_internal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# AzureML workspace info. Note, will look up \"aml_config\\config.json\" first, then fall back to using this\n",
    "SUBSCRIPTION_ID = '<subscription-id>'\n",
    "RESOURCE_GROUP  = '<resource-group>'\n",
    "WORKSPACE_NAME  = '<workspace-name>'\n",
    "\n",
    "# Connect to a workspace\n",
    "try:\n",
    "    ws = aml.core.Workspace.from_config()\n",
    "except aml.exceptions.UserErrorException:\n",
    "    try:\n",
    "        ws = aml.core.Workspace(\n",
    "            subscription_id=SUBSCRIPTION_ID,\n",
    "            resource_group=RESOURCE_GROUP,\n",
    "            workspace_name=WORKSPACE_NAME\n",
    "        )\n",
    "        ws.write_config()\n",
    "    except aml.exceptions.AuthenticationException:\n",
    "        ws = None\n",
    "\n",
    "if ws is None:\n",
    "    raise ValueError(\n",
    "        \"\"\"Cannot access the AzureML workspace w/ the config info provided.\n",
    "        Please check if you entered the correct id, group name and workspace name\"\"\"\n",
    "    )\n",
    "else:\n",
    "    print(\"AzureML workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the following cells, we\n",
    "1. Create a *remote compute target* (cpu_cluster) if it does not exist already,\n",
    "2. Mount a *data store* and upload the training set, and\n",
    "3. Run a hyperparameter tuning experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Remote Compute Target\n",
    "\n",
    "We create an AI Compute for our remote compute target. The script will load the cluster if it already exists. You can look at [this document](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets) to learn more about setting up a *compute target*.\n",
    "\n",
    "> Note: we create a low priority cluster to save costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-02-19T19:24:38.371000+00:00', 'creationTime': '2019-02-06T15:20:44.924560+00:00', 'currentNodeCount': 0, 'errors': None, 'modifiedTime': '2019-02-06T15:21:35.653142+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 0, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Remote compute (cluster) configuration. If you want to save costs decrease these.\n",
    "# Each standard_D2_V2 VM has 2 vCPUs, 7GB memory, 100GB SSD storage\n",
    "\n",
    "VM_SIZE = 'STANDARD_D2_V2'\n",
    "VM_PRIORITY = 'lowpriority'\n",
    "# Cluster nodes\n",
    "MIN_NODES = 4\n",
    "MAX_NODES = 8\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpuclustersvd\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=VM_SIZE, \n",
    "                                                           min_nodes=MIN_NODES, \n",
    "                                                           vm_priority=VM_PRIORITY,\n",
    "                                                           max_nodes=MAX_NODES)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(cpu_cluster.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the configuration of the remote cluster and conda dependencies from the repository yaml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create a new runconfig object\n",
    "run_amlcompute = RunConfiguration()\n",
    "\n",
    "# Use the cpu_cluster you created above. \n",
    "run_amlcompute.target = cpu_cluster\n",
    "\n",
    "# Enable Docker\n",
    "run_amlcompute.environment.docker.enabled = True\n",
    "\n",
    "# Set Docker base image to the default CPU-based image\n",
    "run_amlcompute.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_amlcompute.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Auto-prepare the Docker image when used for execution (if it is not already prepared)\n",
    "run_amlcompute.auto_prepare_environment = True\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "run_amlcompute.environment.python.conda_dependencies = CondaDependencies(conda_dependencies_file_path=\n",
    "                                                                         '../../scripts/reco_base.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "1. Download data and split into training and testing sets\n",
    "2. Upload the training set to the default **blob storage** of the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0     196     242     3.0\n",
       "1     186     302     3.0\n",
       "2      22     377     1.0\n",
       "3     244      51     2.0\n",
       "4     166     346     1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[\"userID\", \"itemID\", \"rating\"]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading aml_data\\movielens_100k_test.pkl\n",
      "Uploading aml_data\\movielens_100k_train.pkl\n",
      "Uploaded aml_data\\movielens_100k_test.pkl, 1 files out of an estimated total of 2\n",
      "Uploaded aml_data\\movielens_100k_train.pkl, 2 files out of an estimated total of 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_191414cceef04504867a7ba9fd31fe87"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'aml_data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_train.pkl\"\n",
    "train.to_pickle(os.path.join(DATA_DIR, TRAIN_FILE_NAME))\n",
    "\n",
    "TEST_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_test.pkl\"\n",
    "test.to_pickle(os.path.join(DATA_DIR, TEST_FILE_NAME))\n",
    "\n",
    "# Note, all the files under DATA_DIR will be uploaded to the data store\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(\n",
    "    src_dir=DATA_DIR,\n",
    "    target_path='data',\n",
    "    overwrite=True,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also prepare a training script [svd_training.py](../../reco_utils/aml/svd_training.py) for the hyperparameter tuning, which will log our target metrics such as [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) and/or [NDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) to AzureML experiment so that we can track the metrics and optimize the primary metric via **hyperdrive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = 'aml_script'\n",
    "\n",
    "# Clean-up scripts if already exists\n",
    "shutil.rmtree(SCRIPT_DIR, ignore_errors=True)\n",
    "\n",
    "# Copy scripts to SCRIPT_DIR temporarly\n",
    "shutil.copytree(os.path.join('..', '..', 'reco_utils'), os.path.join(SCRIPT_DIR, 'reco_utils'))\n",
    "\n",
    "ENTRY_SCRIPT_NAME = 'reco_utils/aml/svd_training.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a search space for the hyperparameters. All the parameter values will be passed to our training script.\n",
    "\n",
    "AzureML hyperdrive provides `RandomParameterSampling`, `GridParameterSampling`, and `BayesianParameterSampling`. Details about each approach are beyond the scope of this notebook and can be found in [Azure doc](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters). Here, we use the Bayesian sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_svd_model\"\n",
    "PRIMARY_METRIC = 'precision_at_k'\n",
    "RATING_METRICS = ['rmse']\n",
    "RANKING_METRICS = ['precision_at_k', 'ndcg_at_k']  \n",
    "USERCOL = 'userID'\n",
    "ITEMCOL = 'itemID'\n",
    "RATINGCOL = 'rating'\n",
    "RECOMMEND_SEEN = False\n",
    "K = 10\n",
    "RANDOM_STATE = 0\n",
    "VERBOSE = True\n",
    "NUM_EPOCHS = 30\n",
    "BIASED = True\n",
    "\n",
    "script_params = {\n",
    "    '--datastore': ds.as_mount(),\n",
    "    '--train-datapath': \"data/\" + TRAIN_FILE_NAME,\n",
    "    '--test-datapath': \"data/\" + TEST_FILE_NAME,\n",
    "    '--surprise-reader': 'ml-100k',\n",
    "    '--rating-metrics': RATING_METRICS,\n",
    "    '--ranking-metrics': RANKING_METRICS,\n",
    "    '--usercol': USERCOL,\n",
    "    '--itemcol': ITEMCOL,\n",
    "    '--ratingcol': RATINGCOL,\n",
    "    '--k': K,\n",
    "    '--random-state': RANDOM_STATE,\n",
    "    '--epochs': NUM_EPOCHS,\n",
    "}\n",
    "\n",
    "if BIASED:\n",
    "    script_params['--biased'] = ''\n",
    "if VERBOSE:\n",
    "    script_params['--verbose'] = ''\n",
    "if RECOMMEND_SEEN:\n",
    "    script_params['--recommend-seen'] = ''\n",
    "    \n",
    "# hyperparameters search space\n",
    "# We do not set 'lr_all' and 'reg_all' because they will be overriden by the other lr_ and reg_ parameters\n",
    "\n",
    "hyper_params = {\n",
    "    'n_factors': hd.choice(10, 50, 100, 150, 200),\n",
    "    'init_mean': hd.uniform(-0.5, 0.5),\n",
    "    'init_std_dev': hd.uniform(0.01, 0.2),\n",
    "    'lr_bu': hd.uniform(1e-6, 0.1), \n",
    "    'lr_bi': hd.uniform(1e-6, 0.1), \n",
    "    'lr_pu': hd.uniform(1e-6, 0.1), \n",
    "    'lr_qi': hd.uniform(1e-6, 0.1), \n",
    "    'reg_bu': hd.uniform(1e-6, 1),\n",
    "    'reg_bi': hd.uniform(1e-6, 1), \n",
    "    'reg_pu': hd.uniform(1e-6, 1), \n",
    "    'reg_qi': hd.uniform(1e-6, 1)\n",
    "}\n",
    "\n",
    "# Note, BayesianParameterSampling only support choice, uniform, and quniform\n",
    "ps = hd.BayesianParameterSampling(hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you submit the experiment, you can see the progress from the notebook by using `azureml.widgets.RunDetails`. You can directly check the details from the Azure portal as well. To get the link, run `run.get_portal_url()`.\n",
    "\n",
    "For RandomSampling, you can use early termnination policy\n",
    "```\n",
    "policy = hd.BanditPolicy(evaluation_interval=1, slack_factor=0.1, delay_evaluation=3)\n",
    "```\n",
    "\n",
    "> Since we will do hyperparameter tuning, we create a `HyperDriveRunConfig` and pass it to the experiment object. If you already know what hyperparameters to use and still want to utilize AzureML for other purposes (e.g. model management), you can set the hyperparameter values directly to `script_params` and run the experiment, `run = exp.submit(est)`, instead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperdrive experimentation configuration\n",
    "MAX_TOTAL_RUNS = 100  # Number of runs (training-and-evaluation) to search for the best hyperparameters. \n",
    "MAX_CONCURRENT_RUNS = 8\n",
    "\n",
    "est = azureml.train.estimator.Estimator(\n",
    "    source_directory=SCRIPT_DIR,\n",
    "    entry_script=ENTRY_SCRIPT_NAME,\n",
    "    script_params=script_params,\n",
    "    compute_target=cpu_cluster,\n",
    "    conda_packages=['pandas', 'scikit-learn'],\n",
    "    pip_packages=['scikit-surprise']\n",
    ")\n",
    "\n",
    "hd_config = hd.HyperDriveRunConfig(\n",
    "    estimator=est, \n",
    "    hyperparameter_sampling=ps,\n",
    "    primary_metric_name=PRIMARY_METRIC,\n",
    "    primary_metric_goal=hd.PrimaryMetricGoal.MAXIMIZE, \n",
    "    max_total_runs=MAX_TOTAL_RUNS,\n",
    "    max_concurrent_runs=MAX_CONCURRENT_RUNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc48cf352a74c58a2dc976ff33421fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: movielens_100k_svd_model_1550672871383\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: movielens_100k_svd_model_1550672871383\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'movielens_100k_svd_model_1550672871383',\n",
       " 'target': 'cpuclustersvd',\n",
       " 'status': 'Completed',\n",
       " 'endTimeUtc': '2019-02-20T15:00:23.000Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"precision_at_k\", \"goal\": \"maximize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://anargyri6699545766.blob.core.windows.net/azureml/ExperimentRun/dcid.movielens_100k_svd_model_1550672871383/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=dt%2BtkHqz49%2F2sQTmTzHDMh%2BchdRdiMSELDnQycGsE3g%3D&st=2019-02-20T14%3A50%3A26Z&se=2019-02-20T23%3A00%3A26Z&sp=r'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an experiment to track the runs in the workspace\n",
    "exp = aml.core.Experiment(workspace=ws, name=EXP_NAME)\n",
    "run = exp.submit(config=hd_config)\n",
    "\n",
    "azureml.widgets.RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best run and printout metrics\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of epochs': 30,\n",
       " 'rmse': 1.1324249983589592,\n",
       " 'precision_at_k': 0.17932131495228,\n",
       " 'ndcg_at_k': 0.20470147010861087}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--datastore $AZUREML_DATAREFERENCE_workspaceblobstore --train-datapath data/movielens_100k_train.pkl --test-datapath data/movielens_100k_test.pkl --surprise-reader ml-100k --rating-metrics rmse --ranking-metrics precision_at_k ndcg_at_k --usercol userID --itemcol itemID --ratingcol rating --k 10 --random-state 0 --epochs 30 --biased --verbose --n_factors 10 --init_mean -0.320173377588374 --init_std_dev 0.10636418973087 --lr_bu 1E-06 --lr_bi 1E-06 --lr_pu 0.0171152526860302 --lr_qi 0.1 --reg_bu 0.180199641033639 --reg_bi 0.963286774529248 --reg_pu 0.994667973995922 --reg_qi 0.673467023866025\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(parameter_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(SCRIPT_DIR)\n",
    "    shutil.rmtree(DATA_DIR)\n",
    "except (PermissionError, FileNotFoundError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [Matrix factorization algorithms in Surprise](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) \n",
    "* [Surprise SVD deep-dive notebook](../02_model/surprise_svd_deep_dive.ipynb)\n",
    "* [Fine-tune natural language processing models using Azure Machine Learning service](https://azure.microsoft.com/en-us/blog/fine-tune-natural-language-processing-models-using-azure-machine-learning-service/)\n",
    "* [Training, hyperparameter tune, and deploy with TensorFlow](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco_base)",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
