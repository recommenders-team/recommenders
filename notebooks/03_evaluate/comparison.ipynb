{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommendation Algorithm Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrative comparison applies to collaborative filtering algorithms available in this repository such as Spark ALS, Surprise SVD and SAR. These algorithms are usable in a variety of recommendation tasks, including product or news recommendations. \n",
    "\n",
    "The main purpose of this notebook is not to produce comprehensive benchmarking results on multiple datasets. Rather, it is intended to illustrate on how one could evaluate different recommender algorithms using tools in this repository.\n",
    "\n",
    "## Experimentation setup:\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in predicting ratings and recommending relevant items.\n",
    "* Environment\n",
    "  * The comparison is run on a [Azure Data Science Virtual Machine](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/). \n",
    "  * The virtual machine size is Standard NC6s_v2 (6 vcpus, 112 GB memory).\n",
    "  * It should be noted that the single node DSVM is not supposed to run scalable benchmarking analysis. Either scaling up or out the computing instances is necessary to run the benchmarking in an run-time efficient way without any memory issue.\n",
    "* Datasets\n",
    "  * [Movielens 100K](https://grouplens.org/datasets/movielens/100k/).\n",
    "  * [Movielens 1M](https://grouplens.org/datasets/movielens/1m/).\n",
    "* Data split\n",
    "  * The data is split into train and test sets.\n",
    "  * The split ratios are 75-25 for train and test datasets.\n",
    "  * The splitting is random. \n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * Empirical parameter values reported [here](http://mymedialite.net/examples/datasets.html) are used in this notebook.  More exhaustive hyper parameter tuning would be required to further optimize results.\n",
    "* Evaluation metrics\n",
    "  * Ranking metrics:\n",
    "    * Precision@k.\n",
    "    * Recall@k.\n",
    "    * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "    * Mean-average-precision (MAP). \n",
    "    * In the evaluation metrics above, k = 10. \n",
    "  * Rating metrics:\n",
    "    * Root mean squared error (RMSE).\n",
    "    * Mean average error (MAE).\n",
    "    * R squared.\n",
    "    * Explained variance.\n",
    "  * Run time performance\n",
    "    * Elapsed for training a model and using a model for predicting/recommending k items. \n",
    "    * The time may vary across different machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.0 | packaged by conda-forge | (default, Feb  9 2017, 14:36:55) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Pandas version: 0.23.4\n",
      "PySpark version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import papermill as pm\n",
    "import pyspark\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"PySpark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temporary directory is created to preserve the output notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put temp results in a temp folder.\n",
    "temp_path = tempfile.mkdtemp()\n",
    "output_path = os.path.join(temp_path, 'output.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global set-up parameters used to run the notebooks.\n",
    "k = 10\n",
    "\n",
    "data_sizes = ['100k', '1m']\n",
    "algorithms = ['als', 'sar', 'svd', 'fast']\n",
    "\n",
    "notebooks = {\n",
    "    'als': '../00_quick_start/als_pyspark_movielens.ipynb',\n",
    "    'sar': '../00_quick_start/sar_single_node_movielens.ipynb',\n",
    "    'svd': '../02_model/surprise_svd_deep_dive.ipynb',\n",
    "    'fast': '../00_quick_start/fastai_recommendation.ipynb'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Run notebooks to generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als 100k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a134ed7fcd34c4f851ce0ff5f36d4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sar 100k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d644713876cd41c19c7acfc7044af007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svd 100k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68737c437fe540f9bf9e223b6802de44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fast 100k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d075d6591da4157a3da2e755bc92d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "als 1m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ef4c360db44c1db5eabaff629aaf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sar 1m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e342cd36d5b24050a10966fc685e7947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svd 1m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a44f9889fdd4b9a84a0e3686aca5cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fast 1m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a5f006bd2540b2a0891c301e3601ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.049102</td>\n",
       "      <td>0.050849</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.948764</td>\n",
       "      <td>0.742875</td>\n",
       "      <td>0.283734</td>\n",
       "      <td>0.288698</td>\n",
       "      <td>3.484409</td>\n",
       "      <td>10.361868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100k</td>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>0.373197</td>\n",
       "      <td>0.326617</td>\n",
       "      <td>0.175957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637508</td>\n",
       "      <td>0.126359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100k</td>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.099960</td>\n",
       "      <td>0.095122</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.957953</td>\n",
       "      <td>0.754764</td>\n",
       "      <td>0.286992</td>\n",
       "      <td>0.287030</td>\n",
       "      <td>10.784497</td>\n",
       "      <td>24.231704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100k</td>\n",
       "      <td>fast</td>\n",
       "      <td>10</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>0.151383</td>\n",
       "      <td>0.135525</td>\n",
       "      <td>0.051316</td>\n",
       "      <td>0.910153</td>\n",
       "      <td>0.718119</td>\n",
       "      <td>0.351431</td>\n",
       "      <td>0.351966</td>\n",
       "      <td>28.978157</td>\n",
       "      <td>1.670263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>0.011404</td>\n",
       "      <td>0.860052</td>\n",
       "      <td>0.680453</td>\n",
       "      <td>0.406634</td>\n",
       "      <td>0.413116</td>\n",
       "      <td>5.761604</td>\n",
       "      <td>25.386441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1m</td>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064013</td>\n",
       "      <td>0.308012</td>\n",
       "      <td>0.277215</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.621757</td>\n",
       "      <td>0.574457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1m</td>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>0.888991</td>\n",
       "      <td>0.696781</td>\n",
       "      <td>0.364178</td>\n",
       "      <td>0.364178</td>\n",
       "      <td>111.618197</td>\n",
       "      <td>370.487794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1m</td>\n",
       "      <td>fast</td>\n",
       "      <td>10</td>\n",
       "      <td>0.023628</td>\n",
       "      <td>0.173430</td>\n",
       "      <td>0.158387</td>\n",
       "      <td>0.051164</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.701237</td>\n",
       "      <td>0.375218</td>\n",
       "      <td>0.378098</td>\n",
       "      <td>276.023314</td>\n",
       "      <td>27.714813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data  Algo   K       MAP    nDCG@k  Precision@k  Recall@k      RMSE  \\\n",
       "0  100k   als  10  0.005850  0.049102     0.050849  0.018680  0.948764   \n",
       "1  100k   sar  10  0.105815  0.373197     0.326617  0.175957       NaN   \n",
       "2  100k   svd  10  0.013018  0.099960     0.095122  0.032043  0.957953   \n",
       "3  100k  fast  10  0.024977  0.151383     0.135525  0.051316  0.910153   \n",
       "4    1m   als  10  0.002514  0.027644     0.034222  0.011404  0.860052   \n",
       "5    1m   sar  10  0.064013  0.308012     0.277215  0.109292       NaN   \n",
       "6    1m   svd  10  0.010915  0.102398     0.092996  0.025362  0.888991   \n",
       "7    1m  fast  10  0.023628  0.173430     0.158387  0.051164  0.881749   \n",
       "\n",
       "        MAE        R2  Explained Variance  Train time   Test time  \n",
       "0  0.742875  0.283734            0.288698    3.484409   10.361868  \n",
       "1       NaN       NaN                 NaN    0.637508    0.126359  \n",
       "2  0.754764  0.286992            0.287030   10.784497   24.231704  \n",
       "3  0.718119  0.351431            0.351966   28.978157    1.670263  \n",
       "4  0.680453  0.406634            0.413116    5.761604   25.386441  \n",
       "5       NaN       NaN                 NaN    6.621757    0.574457  \n",
       "6  0.696781  0.364178            0.364178  111.618197  370.487794  \n",
       "7  0.701237  0.375218            0.378098  276.023314   27.714813  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each data size and each algorithm, a recommender is evaluated. \n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    for algorithm in algorithms:\n",
    "        print(algorithm, data_size)\n",
    "        # Execute the notebook\n",
    "        pm.execute_notebook(\n",
    "            notebooks[algorithm],\n",
    "            output_path,\n",
    "            parameters = dict(TOP_K=k, MOVIELENS_DATA_SIZE=data_size)\n",
    "        )\n",
    "        \n",
    "        # Read records from the notebook.\n",
    "        nb = pm.read_notebook(output_path)\n",
    "        \n",
    "        # Arrange results and save them into dataframe.\n",
    "        df_eval = nb.dataframe.transpose()\n",
    "        df_eval = df_eval.rename(columns=df_eval.iloc[0]).drop(['name', 'type', 'filename'])\n",
    "        df_eval.columns = [x.lower() for x in list(df_eval.columns)]\n",
    "        \n",
    "        if algorithm in [\"als\", \"svd\", \"fast\"]:\n",
    "            df_result = pd.DataFrame(\n",
    "                {\n",
    "                    \"Data\": data_size,\n",
    "                    \"Algo\": algorithm,\n",
    "                    \"K\": k,\n",
    "                    \"MAP\": df_eval['map'].item(),\n",
    "                    \"nDCG@k\": df_eval['ndcg'].item(),\n",
    "                    \"Precision@k\": df_eval['precision'].item(),\n",
    "                    \"Recall@k\": df_eval['recall'].item(),\n",
    "                    \"RMSE\": df_eval['rmse'].item(),\n",
    "                    \"MAE\": df_eval['mae'].item(),\n",
    "                    \"R2\": df_eval['rsquared'].item(),\n",
    "                    \"Explained Variance\": df_eval['exp_var'].item(),\n",
    "                    \"Train time\": df_eval['train_time'].item(),\n",
    "                    \"Test time\": df_eval['test_time'].item()\n",
    "                }, \n",
    "                index=[0]\n",
    "            )\n",
    "        # NOTE SAR algorithm does not predict rating scores so the rating metrics do not apply. \n",
    "        # Therefore, for SAR, the rating metrics are assigned with NAN.\n",
    "        elif algorithm in [\"sar\"]:\n",
    "            df_result = pd.DataFrame(\n",
    "                {\n",
    "                    \"Data\": data_size,\n",
    "                    \"Algo\": algorithm,\n",
    "                    \"K\": k,\n",
    "                    \"MAP\": df_eval['map'].item(),\n",
    "                    \"nDCG@k\": df_eval['ndcg'].item(),\n",
    "                    \"Precision@k\": df_eval['precision'].item(),\n",
    "                    \"Recall@k\": df_eval['recall'].item(),\n",
    "                    \"RMSE\": np.nan,\n",
    "                    \"MAE\": np.nan,\n",
    "                    \"R2\": np.nan,\n",
    "                    \"Explained Variance\": np.nan,\n",
    "                    \"Train time\": df_eval['train_time'].item(),\n",
    "                    \"Test time\": df_eval['test_time'].item()\n",
    "                }, \n",
    "                index=[0]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"{} is not a recognized algorithm\".format(algorithm))\n",
    "        df_results = df_results.append(df_result, ignore_index=True)\n",
    "        \n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporary directory is removed after completion of all runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the temp directory and files.\n",
    "try:\n",
    "    shutil.rmtree(temp_path)  \n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.ENOENT: \n",
    "        raise  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reco2)",
   "language": "python",
   "name": "reco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
