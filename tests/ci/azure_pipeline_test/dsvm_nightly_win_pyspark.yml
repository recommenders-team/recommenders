# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.

schedules:
- cron: "0 06 * * *"
  displayName: Daily master spark testing pipeline
  branches:
    include:
    - master

trigger: none

pr: none

jobs:
- job: nightly
  displayName: 'Nightly tests Windows Pyspark'
  timeoutInMinutes: 180 # how long to run the job before automatically cancelling
  pool:
    name: RecommendersAgentPoolWin

  steps:
  - script: |
    call conda env remove -n nightly_reco_pyspark -y
    rmdir /s /q C:\Anaconda\envs\nightly_reco_pyspark
    displayName: 'Remove Conda Env if it exists'

  - script: |
    python ./scripts/generate_conda_file.py --pyspark --name nightly_reco_pyspark
    conda env create --quiet -f nightly_reco_pyspark.yaml --verbose
    displayName: 'Setup Conda Env'

  - script: |
    call conda activate nightly_reco_pyspark
    set SPARK_HOME=
    echo "Smoke tests"
    pytest tests/smoke --durations 0 -m "smoke and spark and not gpu" --junitxml=reports/test-smoke.xml
    echo "Integration tests"
    pytest tests/integration --durations 0 -m "integration and spark and not gpu" --junitxml=reports/test-integration.xml
    conda deactivate
    displayName: 'Run pyspark smoke and integration tests'
    env:
      PYSPARK_PYTHON: c:\anaconda\envs\reco_pyspark\python.exe
      PYSPARK_DRIVER_PYTHON: c:\anaconda\envs\reco_pyspark\python.exe

  - task: PublishTestResults@2
    displayName: 'Publish Test Results '
    inputs:
      testResultsFiles: '**/test-*.xml'
      failTaskOnFailedTests: true
    condition: succeededOrFailed()

  - script: |
    call conda env remove -n nightly_reco_pyspark -y
    rmdir /s /q C:\Anaconda\envs\nightly_reco_pyspark
    workingDirectory: tests
    displayName: 'Conda remove'
    continueOnError: true
    condition: succeededOrFailed()

