{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bdde4f",
   "metadata": {},
   "source": [
    "# Recommender of Recommenders\n",
    "\n",
    "Using AI Reasoning Models to recommend reco algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924b603",
   "metadata": {},
   "source": [
    "### Step 1: Setup and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9fb55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "\n",
    "# Import necessary libraries and load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file (contains API keys for OpenAI/Azure OpenAI)\n",
    "\n",
    "# Import data modeling and typing libraries\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Union\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Add the current directory to the Python path to allow imports from local modules\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import utility functions and models\n",
    "from utils.file_utils import *      # File handling utilities\n",
    "from utils.openai_utils import *     # OpenAI API interaction utilities\n",
    "from utils.openai_data_models import *  # Data models for API interactions\n",
    "from master_reco.master_reco_models import *  # Models specific to recommendation system\n",
    "\n",
    "# Setup rich console for better output formatting\n",
    "from rich.console import Console\n",
    "console = Console()\n",
    "\n",
    "# Set up directory path and model configuration\n",
    "module_directory = os.path.dirname(\".\")\n",
    "\n",
    "# Configure the OpenAI model to use the \"o3\" model with high reasoning\n",
    "# o3 is a reasoning-focused model that performs well for complex analysis tasks\n",
    "model_info = TextProcessingModelnfo(\n",
    "    model_name=\"o3\",             \n",
    "    reasoning_efforts=\"high\",  # High reasoning effort for detailed analysis   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaed7fd",
   "metadata": {},
   "source": [
    "### Step 2: Define the business scenario for recommendation system analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b540a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scenario description will be used as input to the AI model for analysis\n",
    "scenario = \"\"\"A major task in applying recommendations in retail is to predict which products or set of products a user is most likely to engage with or purchase, based on the shopping or viewing history of that user. This scenario is commonly shown on the personalized home page, feed or newsletter. \n",
    "\n",
    "### You might also like\n",
    "\n",
    "In this scenario, the user is already viewing a product page, and the task is to make recommendations that are relevant to it.  Personalized recommendation techniques are still applicable here, but relevance to the product being viewed is of special importance.  As such, item similarity can be useful here, especially for cold items and cold users that do not have much interaction data.\n",
    "\n",
    "### Frequently bought together\n",
    "\n",
    "In this task, the retailer tries to predict product(s) complementary to or bought together with a  product that a user already put in to shopping cart. This feature is great for cross-selling and is normally displayed just before checkout.  In many cases, a machine learning solution is not required for this task.\n",
    "\n",
    "### Similar alternatives\n",
    "\n",
    "This scenario covers down-selling or out of stock alternatives to avoid losing a sale. Similar alternatives predict other products with similar features, like price, type, brand or visual appearance.\n",
    "\n",
    "## Other considerations\n",
    "\n",
    "Retailers use recommendation to achieve a broad range of business objectives, such as attracting new customers through promotions, or clearing products that are at the end of their season. These objectives are often achieved by re-ranking the outputs from recommenders in scenarios above.\n",
    "\n",
    "\"\"\"\n",
    "# The scenario covers multiple retail recommendation use cases:\n",
    "# 1. Personalized product recommendations based on user history\n",
    "# 2. \"You might also like\" recommendations on product pages\n",
    "# 3. \"Frequently bought together\" for cross-selling\n",
    "# 4. \"Similar alternatives\" for out-of-stock items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f61f51a",
   "metadata": {},
   "source": [
    "### Step 3: Generate algorithm recommendations based on the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7875b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from path: c:\\Users\\selhousseini\\Documents\\GitHub\\recommenders\\examples\\07_tutorials\\ai-reco-of-recos\\prompts\\reco_selection.txt\n",
      ">>>>> https://dev-aoai-swedencentral.openai.azure.com\n",
      "\n",
      "call_llm_structured_o3::Calling OpenAI APIs with 1 messages - Model: o3 - Endpoint: https://dev-aoai-swedencentral.openai.azure.com/openai/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Recommender Selection</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mRecommender Selection\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RankedAlgosResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">ranked_algos</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RankedAlgo</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'SAR'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">why</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'This item-item similarity model excels on implicit events, letting the retailer pre-compute </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“Frequently Bought Together” and context-aware “You Might Also Like” lists with millisecond latency and no heavy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training. SAR scales to large SKU catalogs and still works when user or item history is sparse because it relies on</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simple co-occurrence counts.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RankedAlgo</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LightFM'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">why</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LightFM fuses collaborative signals with product metadata (price, brand, text), so it keeps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recommendations relevant to the product being viewed while mitigating cold-start for new items or users. The hybrid</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">design makes it a strong fit for both personalized home-page feeds and “Similar Alternatives” when the original </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">item is out of stock.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RankedAlgo</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LightGBM-GBT'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">why</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'As a second-stage re-ranker over candidates from SAR/LightFM, LightGBM can directly optimize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">business KPIs such as CVR or margin and inject promotion or clearance rules. It offers fast CPU inference (&lt;100 ms)</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and interpretable feature importance, satisfying real-time retail constraints and merchandising teams alike.'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRankedAlgosResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mranked_algos\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mRankedAlgo\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'SAR'\u001b[0m,\n",
       "            \u001b[33mwhy\u001b[0m=\u001b[32m'This item-item similarity model excels on implicit events, letting the retailer pre-compute \u001b[0m\n",
       "\u001b[32m“Frequently Bought Together” and context-aware “You Might Also Like” lists with millisecond latency and no heavy \u001b[0m\n",
       "\u001b[32mtraining. SAR scales to large SKU catalogs and still works when user or item history is sparse because it relies on\u001b[0m\n",
       "\u001b[32msimple co-occurrence counts.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mRankedAlgo\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'LightFM'\u001b[0m,\n",
       "            \u001b[33mwhy\u001b[0m=\u001b[32m'LightFM fuses collaborative signals with product metadata \u001b[0m\u001b[32m(\u001b[0m\u001b[32mprice, brand, text\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, so it keeps \u001b[0m\n",
       "\u001b[32mrecommendations relevant to the product being viewed while mitigating cold-start for new items or users. The hybrid\u001b[0m\n",
       "\u001b[32mdesign makes it a strong fit for both personalized home-page feeds and “Similar Alternatives” when the original \u001b[0m\n",
       "\u001b[32mitem is out of stock.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mRankedAlgo\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'LightGBM-GBT'\u001b[0m,\n",
       "            \u001b[33mwhy\u001b[0m=\u001b[32m'As a second-stage re-ranker over candidates from SAR/LightFM, LightGBM can directly optimize \u001b[0m\n",
       "\u001b[32mbusiness KPIs such as CVR or margin and inject promotion or clearance rules. It offers fast CPU inference \u001b[0m\u001b[32m(\u001b[0m\u001b[32m<100 ms\u001b[0m\u001b[32m)\u001b[0m\n",
       "\u001b[32mand interpretable feature importance, satisfying real-time retail constraints and merchandising teams alike.'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load the prompt template for recommendation algorithm selection\n",
    "reco_selection_prompt_file = locate_prompt(\"reco_selection.txt\", module_directory)\n",
    "reco_selection_template = read_file(reco_selection_prompt_file)\n",
    "\n",
    "# Step 2: Format the prompt template with our scenario\n",
    "reco_selection_prompt = reco_selection_template.format(scenario=scenario)\n",
    "\n",
    "# Step 3: Call the OpenAI model to analyze the scenario and recommend algorithms\n",
    "# The response will be structured according to the RankedAlgosResponse model\n",
    "reco_selection = call_llm_structured_outputs(\n",
    "    reco_selection_prompt,  # The formatted prompt\n",
    "    model_info=model_info,  # Model configuration (o3 with high reasoning)\n",
    "    response_format=RankedAlgosResponse  # Expected response structure\n",
    ")\n",
    "\n",
    "# Step 4: Display the recommended algorithms with nice formatting\n",
    "console.print(\"\\n[bold green]Recommender Selection[/bold green]\")\n",
    "console.print(reco_selection)\n",
    "# The output will contain ranked recommendation algorithms with explanations\n",
    "# for why each is suitable for the described retail scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b381d0b",
   "metadata": {},
   "source": [
    "### Step 4: Generate a detailed implementation plan based on scenario and algorithm recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef4cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from path: c:\\Users\\selhousseini\\Documents\\GitHub\\master_reco\\prompts\\action_plan.txt\n",
      "\n",
      "call_llm_structured_o3::Calling OpenAI APIs with 1 messages - Model: o3 - Endpoint: https://dev-aoai-swedencentral.openai.azure.com/openai/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Plan of Action</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mPlan of Action\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RecommendationDeploymentPlan</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">candidate_generators</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CandidateGenerator</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'LightGCN graph recall (30-day user–item bipartite)'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">data_needed</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'user_id,item_id, implicit events (view, click, add-to-cart) last 30 days in Delta Lake; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">item metadata for cold-start fallback'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">batch_cadence</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'nightly'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CandidateGenerator</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'BM25 + Azure OpenAI embedding hybrid on item title/description'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">data_needed</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'product_id, title, description, category taxonomy; OpenAI text-embedding-ada-002 vectors </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stored in Azure Cognitive Search index'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">batch_cadence</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'hourly incremental'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CandidateGenerator</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Time-decayed top-Pop (sliding 24 h)'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">data_needed</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'aggregated item interaction counts from Azure Stream Analytics over Event Hub stream'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">batch_cadence</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'near-real-time (5-min micro-batches)'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reranker</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ReRanker</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">architecture</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'xDeepFM (ID embeddings + dense price/brand/ctx features)'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'List-wise LambdaRank with label-gain 2^(click_depth)-1'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">label_definition</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Positive = session click ≥8 s dwell OR add-to-cart within 24 h; negatives = sampled </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unclicked impressions'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">latency_target</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&lt;30 ms per 50 candidates on AKS GPU'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">training_stack</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TrainingStack</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">etl</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'PySpark on Azure Databricks → Delta Lake bronze/silver/gold'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">framework</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'PyTorch Lightning + TorchRec'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">hpo_strategy</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AzureML HyperDrive Bayesian optimisation (20 trials, early-terminate via ASHA)'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">hardware</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1×Standard_NC24ads_A100_v4 (4 × A100 80 GB) + 4 vCPU driver'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">serving_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ServingPath</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">storage</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Redis Enterprise (Azure Cache) for online features; models in Azure ML Managed Endpoint blob </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">store'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ann_layer</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Faiss HNSW (vector recall) hosted in AKS sidecar'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_runtime</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ONNX-Runtime with TensorRT on AKS'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">p99_latency</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'≤50 ms end-to-end (recall 20 ms + re-rank 30 ms)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metrics_rollout</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MetricsRollout</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">offline_metrics</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'nDCG@10'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'MAP@20'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Recall@50'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Coverage'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">online_kpis</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'CTR'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Add-to-Cart Rate'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Revenue per Session'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">rollout_strategy</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Shadow for 48 h ➔ Canary 1% ➔ 5% ➔ 25% ➔ 100% over 3 weeks'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">testing</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Frequentist A/B with sequential testing; holdback 10% control'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">docs_iac</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DocsIac</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">artifacts</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'README.md'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Architecture_diagram.drawio'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'MLflow experiment reports'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Grafana dashboards'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Run-book.md'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">iac_spec</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bicep modules in /infra deploying AKS, Redis, Cognitive Search, AML Workspace'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">monitoring</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Azure Monitor + Application Insights + Prometheus exporters'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRecommendationDeploymentPlan\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcandidate_generators\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mCandidateGenerator\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'LightGCN graph recall \u001b[0m\u001b[32m(\u001b[0m\u001b[32m30-day user–item bipartite\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[33mdata_needed\u001b[0m=\u001b[32m'user_id,item_id, implicit events \u001b[0m\u001b[32m(\u001b[0m\u001b[32mview, click, add-to-cart\u001b[0m\u001b[32m)\u001b[0m\u001b[32m last 30 days in Delta Lake; \u001b[0m\n",
       "\u001b[32mitem metadata for cold-start fallback'\u001b[0m,\n",
       "            \u001b[33mbatch_cadence\u001b[0m=\u001b[32m'nightly'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCandidateGenerator\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'BM25 + Azure OpenAI embedding hybrid on item title/description'\u001b[0m,\n",
       "            \u001b[33mdata_needed\u001b[0m=\u001b[32m'product_id, title, description, category taxonomy; OpenAI text-embedding-ada-002 vectors \u001b[0m\n",
       "\u001b[32mstored in Azure Cognitive Search index'\u001b[0m,\n",
       "            \u001b[33mbatch_cadence\u001b[0m=\u001b[32m'hourly incremental'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mCandidateGenerator\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mmodel\u001b[0m=\u001b[32m'Time-decayed top-Pop \u001b[0m\u001b[32m(\u001b[0m\u001b[32msliding 24 h\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[33mdata_needed\u001b[0m=\u001b[32m'aggregated item interaction counts from Azure Stream Analytics over Event Hub stream'\u001b[0m,\n",
       "            \u001b[33mbatch_cadence\u001b[0m=\u001b[32m'near-real-time \u001b[0m\u001b[32m(\u001b[0m\u001b[32m5-min micro-batches\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mreranker\u001b[0m=\u001b[1;35mReRanker\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33marchitecture\u001b[0m=\u001b[32m'xDeepFM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mID embeddings + dense price/brand/ctx features\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[33mloss\u001b[0m=\u001b[32m'List-wise LambdaRank with label-gain 2^\u001b[0m\u001b[32m(\u001b[0m\u001b[32mclick_depth\u001b[0m\u001b[32m)\u001b[0m\u001b[32m-1'\u001b[0m,\n",
       "        \u001b[33mlabel_definition\u001b[0m=\u001b[32m'Positive = session click ≥8 s dwell OR add-to-cart within 24 h; negatives = sampled \u001b[0m\n",
       "\u001b[32munclicked impressions'\u001b[0m,\n",
       "        \u001b[33mlatency_target\u001b[0m=\u001b[32m'<30 ms per 50 candidates on AKS GPU'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtraining_stack\u001b[0m=\u001b[1;35mTrainingStack\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33metl\u001b[0m=\u001b[32m'PySpark on Azure Databricks → Delta Lake bronze/silver/gold'\u001b[0m,\n",
       "        \u001b[33mframework\u001b[0m=\u001b[32m'PyTorch Lightning + TorchRec'\u001b[0m,\n",
       "        \u001b[33mhpo_strategy\u001b[0m=\u001b[32m'AzureML HyperDrive Bayesian optimisation \u001b[0m\u001b[32m(\u001b[0m\u001b[32m20 trials, early-terminate via ASHA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[33mhardware\u001b[0m=\u001b[32m'1×Standard_NC24ads_A100_v4 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m4 × A100 80 GB\u001b[0m\u001b[32m)\u001b[0m\u001b[32m + 4 vCPU driver'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mserving_path\u001b[0m=\u001b[1;35mServingPath\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mstorage\u001b[0m=\u001b[32m'Redis Enterprise \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAzure Cache\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for online features; models in Azure ML Managed Endpoint blob \u001b[0m\n",
       "\u001b[32mstore'\u001b[0m,\n",
       "        \u001b[33mann_layer\u001b[0m=\u001b[32m'Faiss HNSW \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvector recall\u001b[0m\u001b[32m)\u001b[0m\u001b[32m hosted in AKS sidecar'\u001b[0m,\n",
       "        \u001b[33mmodel_runtime\u001b[0m=\u001b[32m'ONNX-Runtime with TensorRT on AKS'\u001b[0m,\n",
       "        \u001b[33mp99_latency\u001b[0m=\u001b[32m'≤50 ms end-to-end \u001b[0m\u001b[32m(\u001b[0m\u001b[32mrecall 20 ms + re-rank 30 ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mmetrics_rollout\u001b[0m=\u001b[1;35mMetricsRollout\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33moffline_metrics\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'nDCG@10'\u001b[0m, \u001b[32m'MAP@20'\u001b[0m, \u001b[32m'Recall@50'\u001b[0m, \u001b[32m'Coverage'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33monline_kpis\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'CTR'\u001b[0m, \u001b[32m'Add-to-Cart Rate'\u001b[0m, \u001b[32m'Revenue per Session'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mrollout_strategy\u001b[0m=\u001b[32m'Shadow for 48 h ➔ Canary 1% ➔ 5% ➔ 25% ➔ 100% over 3 weeks'\u001b[0m,\n",
       "        \u001b[33mtesting\u001b[0m=\u001b[32m'Frequentist A/B with sequential testing; holdback 10% control'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdocs_iac\u001b[0m=\u001b[1;35mDocsIac\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33martifacts\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[32m'README.md'\u001b[0m,\n",
       "            \u001b[32m'Architecture_diagram.drawio'\u001b[0m,\n",
       "            \u001b[32m'MLflow experiment reports'\u001b[0m,\n",
       "            \u001b[32m'Grafana dashboards'\u001b[0m,\n",
       "            \u001b[32m'Run-book.md'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33miac_spec\u001b[0m=\u001b[32m'Bicep modules in /infra deploying AKS, Redis, Cognitive Search, AML Workspace'\u001b[0m,\n",
       "        \u001b[33mmonitoring\u001b[0m=\u001b[32m'Azure Monitor + Application Insights + Prometheus exporters'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load the prompt template for the action plan\n",
    "action_plan_prompt_file = locate_prompt(\"action_plan.txt\", module_directory)\n",
    "action_plan_template = read_file(action_plan_prompt_file)\n",
    "\n",
    "# Step 2: Format the prompt with both the scenario and the recommended algorithms\n",
    "# This allows the model to create a plan specifically for the selected algorithms\n",
    "action_plan_prompt = action_plan_template.format(\n",
    "    scenario=scenario, \n",
    "    algos=str(reco_selection.model_dump())  # Convert the algorithm recommendations to a string\n",
    ")\n",
    "\n",
    "# Step 3: Call the OpenAI model to generate a detailed implementation plan\n",
    "# The response will be structured according to the RecommendationDeploymentPlan model\n",
    "plan_of_action = call_llm_structured_outputs(\n",
    "    action_plan_prompt, \n",
    "    model_info=model_info,\n",
    "    response_format=RecommendationDeploymentPlan  # Expected response structure\n",
    ")\n",
    "\n",
    "# Step 4: Display the implementation plan with nice formatting\n",
    "console.print(\"\\n[bold green]Plan of Action[/bold green]\")\n",
    "console.print(plan_of_action)\n",
    "# The output will contain a comprehensive implementation plan including:\n",
    "# - Candidate recommendation generators\n",
    "# - Re-ranking strategies\n",
    "# - Training infrastructure requirements\n",
    "# - Serving architecture on Azure\n",
    "# - Evaluation metrics and rollout strategy\n",
    "# - Documentation and Infrastructure as Code specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5590d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
