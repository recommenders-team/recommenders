{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
        "\n",
        "<i>Licensed under the MIT License.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NRMS: Neural News Recommendation with Multi-Head Self-Attention\n",
        "NRMS \\[1\\] is a neural news recommendation approach with multi-head selfattention. The core of NRMS is a news encoder and a user encoder. In the newsencoder, a multi-head self-attentions is used to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multihead self-attention to capture the relatedness between the news. Besides, we apply additive\n",
        "attention to learn more informative news and user representations by selecting important words and news.\n",
        "\n",
        "## Properties of NRMS:\n",
        "- NRMS is a content-based neural news recommendation approach.\n",
        "- It uses multi-self attention to learn news representations by modeling the iteractions between words and learn user representations by capturing the relationship between user browsed news.\n",
        "- NRMS uses additive attentions to learn informative news and user representations by selecting important words and news.\n",
        "\n",
        "## Data format:\n",
        "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
        " \n",
        "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
        "\n",
        "### news data\n",
        "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
        "One simple example: <br>\n",
        "\n",
        "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
        "<br>\n",
        "\n",
        "In general, each line in data file represents information of one piece of news: <br>\n",
        "\n",
        "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
        "\n",
        "<br>\n",
        "\n",
        "We generate a word_dict file to transform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
        "\n",
        "### behaviors data\n",
        "One simple example: <br>\n",
        "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
        "<br>\n",
        "\n",
        "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
        "\n",
        "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
        "\n",
        "<br>\n",
        "\n",
        "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
        "\n",
        "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
        "\n",
        "<br>\n",
        "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Global settings and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1676232193942
        },
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System version: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
            "[GCC 7.5.0]\n",
            "Tensorflow version: 2.7.4\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import scrapbook as sb\n",
        "from tempfile import TemporaryDirectory\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
        "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
        "from recommenders.models.newsrec.models.nrms import NRMSModel\n",
        "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
        "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System version: 3.8.10 (default, Jun  4 2021, 15:09:15) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import numpy as np\n",
        "import scrapbook as sb\n",
        "\n",
        "from tempfile import TemporaryDirectory\n",
        "from recommenders.datasets.mind import (download_mind,\n",
        "                                     extract_mind,\n",
        "                                     download_and_extract_glove,\n",
        "                                     load_glove_matrix,\n",
        "                                     word_tokenize\n",
        "                                    )\n",
        "from recommenders.datasets.download_utils import unzip_file\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "seed = 42\n",
        "batch_size = 32\n",
        "\n",
        "# Options: demo, small, large\n",
        "MIND_type = 'demo'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/tmp/tmpagjsd92l'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmpdir = TemporaryDirectory()\n",
        "tmpdir.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmpdir = TemporaryDirectory()\n",
        "data_path = \"/home/azureuser/cloudfiles/code/Users/lab164/recommenders/data\"\n",
        "#tmpdir.name\n",
        "\n",
        "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
        "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
        "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
        "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
        "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
        "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
        "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
        "yaml_file = os.path.join(data_path, \"utils\", r'nrms.yaml')\n",
        "\n",
        "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
        "\n",
        "if not os.path.exists(train_news_file):\n",
        "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
        "    \n",
        "if not os.path.exists(valid_news_file):\n",
        "    download_deeprec_resources(mind_url, \\\n",
        "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
        "if not os.path.exists(yaml_file):\n",
        "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
        "                               os.path.join(data_path, 'utils'), mind_utils)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read some datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>newid</th>\n",
              "      <th>vertical</th>\n",
              "      <th>subvertical</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N3112</td>\n",
              "      <td>lifestyle</td>\n",
              "      <td>lifestyleroyals</td>\n",
              "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
              "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N10399</td>\n",
              "      <td>news</td>\n",
              "      <td>newsworld</td>\n",
              "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
              "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N12103</td>\n",
              "      <td>health</td>\n",
              "      <td>voices</td>\n",
              "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
              "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N20460</td>\n",
              "      <td>health</td>\n",
              "      <td>medical</td>\n",
              "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
              "      <td>They seem harmless, but there's a very good re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N5409</td>\n",
              "      <td>weather</td>\n",
              "      <td>weathertopstories</td>\n",
              "      <td>It's been Orlando's hottest October ever so fa...</td>\n",
              "      <td>There won't be a chill down to your bones this...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    newid   vertical        subvertical  \\\n",
              "0   N3112  lifestyle    lifestyleroyals   \n",
              "1  N10399       news          newsworld   \n",
              "2  N12103     health             voices   \n",
              "3  N20460     health            medical   \n",
              "4   N5409    weather  weathertopstories   \n",
              "\n",
              "                                               title  \\\n",
              "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
              "1  The Cost of Trump's Aid Freeze in the Trenches...   \n",
              "2  I Was An NBA Wife. Here's How It Affected My M...   \n",
              "3  How to Get Rid of Skin Tags, According to a De...   \n",
              "4  It's been Orlando's hottest October ever so fa...   \n",
              "\n",
              "                                            abstract  \n",
              "0  Shop the notebooks, jackets, and more that the...  \n",
              "1  Lt. Ivan Molchanets peeked over a parapet of s...  \n",
              "2  I felt like I was a fraud, and being an NBA wi...  \n",
              "3  They seem harmless, but there's a very good re...  \n",
              "4  There won't be a chill down to your bones this...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news = pd.read_table(os.path.join(data_path, 'train', 'news.tsv'),\n",
        "                     names=['newid', 'vertical', 'subvertical', 'title',\n",
        "                            'abstract', 'url', 'entities in title', 'entities in abstract'],\n",
        "                     usecols = ['newid','vertical', 'subvertical', 'title', 'abstract'])\n",
        "\n",
        "news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>U82271</th>\n",
              "      <th>11/11/2019 3:28:58 PM</th>\n",
              "      <th>N3130 N11621 N12917 N4574 N12140 N9748</th>\n",
              "      <th>N13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>U84185</td>\n",
              "      <td>11/12/2019 10:36:47 AM</td>\n",
              "      <td>N27209 N11723 N4617 N12320 N11333 N24461 N2211...</td>\n",
              "      <td>N13089-0 N18101-0 N1248-0 N26273-0 N12770-1 N1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>U11552</td>\n",
              "      <td>11/11/2019 1:03:52 PM</td>\n",
              "      <td>N2139</td>\n",
              "      <td>N18390-0 N10537-0 N23967-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>U68381</td>\n",
              "      <td>11/11/2019 6:44:05 AM</td>\n",
              "      <td>N27420 N11621 N25416 N25457 N5124 N11751 N1175...</td>\n",
              "      <td>N15660-0 N18609-0 N2831-0 N5677-0 N19010-0 N15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>U52303</td>\n",
              "      <td>11/12/2019 3:11:52 AM</td>\n",
              "      <td>N1332 N12667</td>\n",
              "      <td>N15645-0 N7911-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>U26536</td>\n",
              "      <td>11/11/2019 3:13:36 PM</td>\n",
              "      <td>N17674 N7165 N18669 N20855 N9748 N44 N24245 N2...</td>\n",
              "      <td>N15244-0 N2167-0 N20122-0 N16945-0 N9480-0 N36...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   1  U82271   11/11/2019 3:28:58 PM  \\\n",
              "0  2  U84185  11/12/2019 10:36:47 AM   \n",
              "1  3  U11552   11/11/2019 1:03:52 PM   \n",
              "2  4  U68381   11/11/2019 6:44:05 AM   \n",
              "3  5  U52303   11/12/2019 3:11:52 AM   \n",
              "4  6  U26536   11/11/2019 3:13:36 PM   \n",
              "\n",
              "              N3130 N11621 N12917 N4574 N12140 N9748  \\\n",
              "0  N27209 N11723 N4617 N12320 N11333 N24461 N2211...   \n",
              "1                                              N2139   \n",
              "2  N27420 N11621 N25416 N25457 N5124 N11751 N1175...   \n",
              "3                                       N1332 N12667   \n",
              "4  N17674 N7165 N18669 N20855 N9748 N44 N24245 N2...   \n",
              "\n",
              "  N13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0  \n",
              "0  N13089-0 N18101-0 N1248-0 N26273-0 N12770-1 N1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "1                         N18390-0 N10537-0 N23967-1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "2  N15660-0 N18609-0 N2831-0 N5677-0 N19010-0 N15...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "3                                   N15645-0 N7911-1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "4  N15244-0 N2167-0 N20122-0 N16945-0 N9480-0 N36...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "behaviours = pd.read_table(os.path.join(data_path, 'train', 'behaviors.tsv'),\n",
        "                    )\n",
        "\n",
        "behaviours.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_format=news,iterator_type=None,support_quick_scoring=True,wordEmb_file=/tmp/tmp1z4450vf/utils/embedding.npy,wordDict_file=/tmp/tmp1z4450vf/utils/word_dict.pkl,userDict_file=/tmp/tmp1z4450vf/utils/uid2index.pkl,vertDict_file=None,subvertDict_file=None,title_size=30,body_size=None,word_emb_dim=300,word_size=None,user_num=None,vert_num=None,subvert_num=None,his_size=50,npratio=4,dropout=0.2,attention_hidden_dim=200,head_num=20,head_dim=20,cnn_activation=None,dense_activation=None,filter_num=200,window_size=3,vert_emb_dim=100,subvert_emb_dim=100,gru_unit=400,type=ini,user_emb_dim=50,learning_rate=0.0001,loss=cross_entropy_loss,optimizer=adam,epochs=5,batch_size=32,show_step=10,metrics=['group_auc', 'mean_mrr', 'ndcg@5;10']\n"
          ]
        }
      ],
      "source": [
        "hparams = prepare_hparams(yaml_file, \n",
        "                          wordEmb_file=wordEmb_file,\n",
        "                          wordDict_file=wordDict_file, \n",
        "                          userDict_file=userDict_file,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          show_step=10)\n",
        "print(hparams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the NRMS model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "iterator = MINDIterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model = NRMSModel(hparams, iterator, seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "586it [00:02, 238.86it/s]\n",
            "236it [00:04, 57.82it/s]\n",
            "7538it [00:01, 6381.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.4792, 'mean_mrr': 0.2059, 'ndcg@5': 0.2045, 'ndcg@10': 0.2701}\n"
          ]
        }
      ],
      "source": [
        "print(model.run_eval(valid_news_file, valid_behaviors_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "step 1080 , total_loss: 1.5155, data_loss: 1.4078: : 1086it [01:07, 16.10it/s]\n",
            "586it [00:01, 388.70it/s]\n",
            "236it [00:03, 68.28it/s]\n",
            "7538it [00:00, 7543.81it/s]\n",
            "2it [00:00, 16.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 1\n",
            "train info: logloss loss:1.5149870059327746\n",
            "eval info: group_auc:0.5755, mean_mrr:0.2453, ndcg@10:0.3313, ndcg@5:0.2587\n",
            "at epoch 1 , train time: 67.4 eval time: 13.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "step 1080 , total_loss: 1.4203, data_loss: 1.3752: : 1086it [01:04, 16.93it/s]\n",
            "586it [00:01, 412.04it/s]\n",
            "236it [00:03, 67.25it/s]\n",
            "7538it [00:00, 9040.56it/s]\n",
            "2it [00:00, 16.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 2\n",
            "train info: logloss loss:1.4203101933331779\n",
            "eval info: group_auc:0.5995, mean_mrr:0.2572, ndcg@10:0.3482, ndcg@5:0.273\n",
            "at epoch 2 , train time: 64.2 eval time: 13.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "step 1080 , total_loss: 1.3770, data_loss: 1.2186: : 1086it [01:05, 16.49it/s]\n",
            "586it [00:01, 401.41it/s]\n",
            "236it [00:03, 65.66it/s]\n",
            "7538it [00:00, 7954.16it/s]\n",
            "2it [00:00, 16.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 3\n",
            "train info: logloss loss:1.3768525854658686\n",
            "eval info: group_auc:0.6032, mean_mrr:0.2632, ndcg@10:0.3535, ndcg@5:0.2817\n",
            "at epoch 3 , train time: 65.9 eval time: 13.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "step 1080 , total_loss: 1.3516, data_loss: 1.2423: : 1086it [01:06, 16.39it/s]\n",
            "586it [00:01, 390.04it/s]\n",
            "236it [00:03, 64.53it/s]\n",
            "7538it [00:01, 5913.76it/s]\n",
            "2it [00:00, 16.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 4\n",
            "train info: logloss loss:1.3515781479755598\n",
            "eval info: group_auc:0.6107, mean_mrr:0.2662, ndcg@10:0.3577, ndcg@5:0.2857\n",
            "at epoch 4 , train time: 66.2 eval time: 13.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "step 1080 , total_loss: 1.3297, data_loss: 1.2343: : 1086it [01:06, 16.37it/s]\n",
            "586it [00:01, 391.49it/s]\n",
            "236it [00:03, 64.32it/s]\n",
            "7538it [00:00, 7717.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 5\n",
            "train info: logloss loss:1.330019418157047\n",
            "eval info: group_auc:0.6127, mean_mrr:0.2697, ndcg@10:0.3625, ndcg@5:0.2912\n",
            "at epoch 5 , train time: 66.3 eval time: 14.2\n",
            "CPU times: user 8min 12s, sys: 15.5 s, total: 8min 27s\n",
            "Wall time: 6min 37s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<recommenders.models.newsrec.models.nrms.NRMSModel at 0x7f14d45b5a58>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "586it [00:01, 396.35it/s]\n",
            "236it [00:03, 67.56it/s]\n",
            "7538it [00:01, 6017.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.6127, 'mean_mrr': 0.2697, 'ndcg@5': 0.2912, 'ndcg@10': 0.3625}\n",
            "CPU times: user 29.8 s, sys: 1.27 s, total: 31.1 s\n",
            "Wall time: 14.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
        "print(res_syn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sb.glue(\"res_syn\", res_syn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = os.path.join(data_path, \"model\")\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "model.model.save_weights(os.path.join(model_path, \"nrms_ckpt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output Predcition File\n",
        "This code segment is used to generate the prediction.zip file, which is in the same format in [MIND Competition Submission Tutorial](https://competitions.codalab.org/competitions/24122#learn_the_details-submission-guidelines).\n",
        "\n",
        "Please change the `MIND_type` parameter to `large` if you want to submit your prediction to [MIND Competition](https://msnews.github.io/competition.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "586it [00:01, 399.64it/s]\n",
            "236it [00:03, 67.94it/s]\n",
            "7538it [00:00, 8052.34it/s]\n"
          ]
        }
      ],
      "source": [
        "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7538it [00:00, 35200.73it/s]\n"
          ]
        }
      ],
      "source": [
        "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
        "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
        "        impr_index += 1\n",
        "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
        "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
        "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
        "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reference\n",
        "\\[1\\] Wu et al. \"Neural News Recommendation with Multi-Head Self-Attention.\" in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<br>\n",
        "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
        "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "interpreter": {
      "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
