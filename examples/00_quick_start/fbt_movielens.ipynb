{
 "cells": [
  {
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# FBT Single Node on MovieLens (Python, CPU)\n",
    "\n",
    "Lets say you are shopping online and you'd like to buy a Microsoft Surface tablet. You might add this to your shopping cart. You may then see on your screen a phrase similar to \"Frequently bought together\" with visuals and links to a Microsoft keyboard, a tablet case, a mouse and so on. Many recommendation algorithms can enable this feature under the hood. However, one of the simplest ones is exactly as the phrase describes - What are some other items that people bought along with a Microsoft surface? Which of these items are the most popular? That is essentially what is implemented in the FBT (Frequently bought together) recommender class which we work with in this notebook.\n",
    "\n",
    "FBT recommender can be thought of a simple restriction of the SAR (Simple Algorithm for Recommendation) recommender. Like SAR, FBT is a fast and scalable algorithm for personalized recommendations based on user transaction history. SAR leverages user ratings of items and timestamp information of when user rated an item to produce easily explainable and interpretable recommendations. However, there are many scenarios where we may not have reliable rating information or timestamps. All we have is user interactions with items and we need a simple recommendation engine that can leverage this interaction information without regard to context or quality of interaction or when in history did this interaction happen.\n",
    "\n",
    "This is where we can leverage FBT. Like SAR, FBT recommends items that are most ***similar*** to the ones that the user already has an existing ***affinity*** for. Two items are ***similar*** if the users that interacted with one item are also likely to have interacted with the other. Unlike SAR though, user ***affinity*** to an item is simply binary - 1 if the user has interacted with an item in the past, 0 otherwise. We don't associate quality of this interaction for this model that rating information can typically do for us.\n",
    "\n",
    "### Advantages of FBT:\n",
    "- A simple first algorithm to implement when all you have is users and items and no more information. Covers a broad range of customer scenarios.\n",
    "- High accuracy for an easy to train and deploy algorithm\n",
    "- Fast training and scoring, only requiring simple counting to construct matrices used at prediction time.\n",
    "- Easily scalable to implement in Spark for large tables of user-item interactions.\n",
    "\n",
    "### Notes to use FBT properly:\n",
    "- Since FBT uses very little information, recommendations will likely not have more context than historical interactions. If we can leverage useful information from item or user features, more sohisticated algorithms will have an edge in performance.\n",
    "\n",
    "- It's memory-hungry, requiring the creation of an $mxm$ sparse square matrix (where $m$ is the number of items). This can also be a problem for many matrix factorization algorithms.\n",
    "- FBT does not need ratings information, hence we can't predict ratings either. Evaluation can best happen with user studies. We can still look at offline evaluation methods like Precision@K, Recall@K.\n",
    "\n",
    "This notebook provides an example of how to utilize and evaluate FBT in Python on a CPU."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'reco_utils'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-97b5fe3f830a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminmax_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mreco_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreco_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreco_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmovielens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'reco_utils'"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import reco_utils\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from reco_utils.common.python_utils import binarize\n",
    "from reco_utils.common.timer import Timer\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_stratified_split\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    logloss,\n",
    "    rsquared,\n",
    "    exp_var,\n",
    "    get_top_k_items\n",
    ")\n",
    "from reco_utils.recommender.fbt.fbt import FBT\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download and use the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:02<00:00, 1.67kKB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id  item_id_name\n",
       "0      196      242  Kolya (1996)\n",
       "1       63      242  Kolya (1996)\n",
       "2      226      242  Kolya (1996)\n",
       "3      154      242  Kolya (1996)\n",
       "4      306      242  Kolya (1996)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>item_id_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>226</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>306</td>\n      <td>242</td>\n      <td>Kolya (1996)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "col_user = 'user_id'\n",
    "col_item = 'item_id'\n",
    "col_item_name = f'{col_item}_name'\n",
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=(col_user, col_item),\n",
    "    title_col=col_item_name\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the data using the python random splitter provided in utilities:\n",
    "\n",
    "We split the full dataset into a `train` and `test` dataset to evaluate performance of the algorithm against a held-out set not seen during training. Because FBT generates recommendations based on user preferences, all users that are in the test set must also exist in the training set. For this case, we can use the provided `python_stratified_split` function which holds out a percentage (in this case 25%) of items from each user, but ensures all users are in both `train` and `test` datasets. Other options are available in the `dataset.python_splitters` module which provide more control over how the split occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(data, \n",
    "                                      ratio=0.75, \n",
    "                                      col_user=col_user, \n",
    "                                      col_item=col_item, \n",
    "                                      seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTrain:\nTotal Ratings: 74992\nUnique Users: 943\nUnique Items: 1601\n\nTest:\nTotal Ratings: 25008\nUnique Users: 943\nUnique Items: 1532\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train[col_user].unique()),\n",
    "    train_items=len(train[col_item].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test[col_user].unique()),\n",
    "    test_items=len(test[col_item].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Train the FBT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "col_score = 'score'\n",
    "model = FBT(\n",
    "    col_user=col_user,\n",
    "    col_item=col_item,\n",
    "    col_score=col_score,\n",
    "    num_recos=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-17 15:31:24,968 INFO     Check dataframe is of the type, schema we expect\n",
      "2021-06-17 15:31:24,992 INFO     De-duplicating the user-item counts\n",
      "2021-06-17 15:31:27,665 INFO     Done training\n",
      "Took 2.7274963530071545 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         item_id  item_id_paired  score\n1              1               2     61\n2              1               3     51\n3              1               4     91\n4              1               5     41\n5              1               6      7\n...          ...             ...    ...\n1597431     1680            1313      1\n1597432     1680            1395      1\n1597433     1680            1607      1\n1597434     1680            1678      1\n1597435     1680            1679      1\n\n[1595836 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>item_id_paired</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1597431</th>\n      <td>1680</td>\n      <td>1313</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597432</th>\n      <td>1680</td>\n      <td>1395</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597433</th>\n      <td>1680</td>\n      <td>1607</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597434</th>\n      <td>1680</td>\n      <td>1678</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1597435</th>\n      <td>1680</td>\n      <td>1679</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1595836 rows × 3 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# The model object is an item-item co-occurence matrix\n",
    "# Score here is number of unique users who have \n",
    "# interacted with both items\n",
    "display(model._model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         score\nitem_id       \n50         451\n100        425\n288        419\n181        413\n1          395\n...        ...\n1447         1\n1452         1\n1453         1\n1458         1\n1680         1\n\n[1601 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n    <tr>\n      <th>item_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>50</th>\n      <td>451</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>425</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>419</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>413</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>395</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1447</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1452</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1453</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1680</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1601 rows × 1 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Which are the \"popular\" (most user-interactions) items?\n",
    "display(model.item_frequencies.sort_values('score', ascending=False).set_index(model.col_item))"
   ]
  },
  {
   "source": [
    "# 3. Make recommendations using the FBT model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All recommended items for each user\n",
    "with Timer() as predict_time:\n",
    "    all_recos = model.predict(test)\n",
    "print(\"Took {} seconds for prediction.\".format(predict_time.interval))\n",
    "all_recos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-17 15:46:27,266 INFO     Calculating recommendation scores\n",
      "2021-06-17 15:46:30,814 INFO     De-duplicating the user-item counts\n",
      "/Users/prasanna/opt/anaconda3/envs/reco_base/lib/python3.6/site-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "Took 5.143892934022006 seconds for prediction.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   user_id  item_id      score  rank\n0        1       98  55.149254     1\n1        1       56  50.283582     2\n2        1       69  47.925373     3\n3        1      423  47.720588     4\n4        1      204  46.970149     5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>98</td>\n      <td>55.149254</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>56</td>\n      <td>50.283582</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>69</td>\n      <td>47.925373</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>423</td>\n      <td>47.720588</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>204</td>\n      <td>46.970149</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Predict 10 recommended items that user has not interacted with during training\n",
    "with Timer() as test_time:\n",
    "    topk_remove_seen = model.recommend_k_items(test=test, \n",
    "                                               top_k=10, \n",
    "                                               remove_seen=True, \n",
    "                                               train=train)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))\n",
    "display(topk_remove_seen.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-17 15:52:08,819 INFO     Calculating recommendation scores\n",
      "Took 4.676356565993046 seconds for prediction.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   user_id  item_id      score  rank\n0        1       50  66.735294     1\n1        1      181  61.397059     2\n2        1      174  59.544118     3\n3        1        1  56.985294     4\n4        1       98  55.149254     5\n5        1      100  54.455882     6\n6        1      172  54.411765     7\n7        1      210  53.500000     8\n8        1       79  51.611940     9\n9        1      222  50.823529    10",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>50</td>\n      <td>66.735294</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>181</td>\n      <td>61.397059</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>174</td>\n      <td>59.544118</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>56.985294</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>98</td>\n      <td>55.149254</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>100</td>\n      <td>54.455882</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>172</td>\n      <td>54.411765</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>210</td>\n      <td>53.500000</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>79</td>\n      <td>51.611940</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>222</td>\n      <td>50.823529</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Predict 10 recommendations while retaining any items \n",
    "# user has already interacted with during training\n",
    "with Timer() as test_time:\n",
    "    topk_keep_seen = model.recommend_k_items(test=test, top_k=10, remove_seen=False)\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))\n",
    "display(topk_keep_seen.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   user_id  item_id      score  rank                       item_id_name\n0        1       98  55.149254     1   Silence of the Lambs, The (1991)\n1        1       56  50.283582     2                Pulp Fiction (1994)\n2        1       69  47.925373     3                Forrest Gump (1994)\n3        1      423  47.720588     4  E.T. the Extra-Terrestrial (1982)\n4        1      204  46.970149     5          Back to the Future (1985)\n5        1      288  46.941176     6                      Scream (1996)\n6        1      117  44.597015     7                   Rock, The (1996)\n7        1      294  43.166667     8                   Liar Liar (1997)\n8        1      183  42.939394     9                       Alien (1979)\n9        1      238  42.358209    10             Raising Arizona (1987)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>score</th>\n      <th>rank</th>\n      <th>item_id_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>98</td>\n      <td>55.149254</td>\n      <td>1</td>\n      <td>Silence of the Lambs, The (1991)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>56</td>\n      <td>50.283582</td>\n      <td>2</td>\n      <td>Pulp Fiction (1994)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>69</td>\n      <td>47.925373</td>\n      <td>3</td>\n      <td>Forrest Gump (1994)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>423</td>\n      <td>47.720588</td>\n      <td>4</td>\n      <td>E.T. the Extra-Terrestrial (1982)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>204</td>\n      <td>46.970149</td>\n      <td>5</td>\n      <td>Back to the Future (1985)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>288</td>\n      <td>46.941176</td>\n      <td>6</td>\n      <td>Scream (1996)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>117</td>\n      <td>44.597015</td>\n      <td>7</td>\n      <td>Rock, The (1996)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>294</td>\n      <td>43.166667</td>\n      <td>8</td>\n      <td>Liar Liar (1997)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>183</td>\n      <td>42.939394</td>\n      <td>9</td>\n      <td>Alien (1979)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>238</td>\n      <td>42.358209</td>\n      <td>10</td>\n      <td>Raising Arizona (1987)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Adding titles of recommended items for novel recommendations not seen during training\n",
    "topk_remove_seen_with_titles = (\n",
    "    topk_remove_seen.merge((\n",
    "        data.loc[:, [col_item, col_item_name]]\n",
    "            .drop_duplicates()\n",
    "            .set_index(col_item)\n",
    "    ), on=col_item, how='inner')\n",
    "    .sort_values(by=[col_user, col_score], ascending=[True, False])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "        \n",
    "display(topk_remove_seen_with_titles.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Evaluate how well FBT performs\n",
    "\n",
    "We evaluate how well FBT performs for a few common ranking metrics provided in the `python_evaluation` module in reco_utils. We will consider the Mean Average Precision (MAP), Normalized Discounted Cumalative Gain (NDCG), Precision, and Recall for the top-k items per user we computed with FBT. User and item column names are specified in each evaluation method. Since FBT does not have ratings information, we create a dummy column with all values set to 1.0 so as to conform to the metrics signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAP@10: 0.044028595315000515\n"
     ]
    }
   ],
   "source": [
    "test['rating'] = 1\n",
    "eval_map_k = map_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score,k=TOP_K)\n",
    "print(f\"MAP@{TOP_K}: {eval_map_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NDCG@10: 0.2443432424633656\n"
     ]
    }
   ],
   "source": [
    "eval_ndcg = ndcg_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "print(f\"NDCG@{TOP_K}: {eval_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision@10: 0.2292682926829268\n"
     ]
    }
   ],
   "source": [
    "eval_precision = precision_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "print(f\"Precision@{TOP_K}: {eval_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall@10: 0.09436047878760673\n"
     ]
    }
   ],
   "source": [
    "eval_recall = recall_at_k(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score, k=TOP_K)\n",
    "print(f\"Recall@{TOP_K}: {eval_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 65.1847870130108\n"
     ]
    }
   ],
   "source": [
    "eval_rmse = rmse(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score)\n",
    "print(f\"RMSE: {eval_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 62.78606036179992\n"
     ]
    }
   ],
   "source": [
    "eval_mae = mae(test, topk_remove_seen, col_user=col_user, col_item=col_item, col_prediction=col_score)\n",
    "print(f\"MAE: {eval_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model:\t\nTop K: 10\nMAP@10: 0.044028595315000515\nNDCG@10: 0.2443432424633656\nPrecision@10: 0.2292682926829268\nRecall@10: 0.09436047878760673\nRMSE: 65.1847870130108\nMAE: 62.78606036179992\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model:\\t\",\n",
    "      f\"Top K: {TOP_K}\",\n",
    "      f\"MAP@{TOP_K}: {eval_map_k}\",\n",
    "      f\"NDCG@{TOP_K}: {eval_ndcg}\",\n",
    "      f\"Precision@{TOP_K}: {eval_precision}\",\n",
    "      f\"Recall@{TOP_K}: {eval_recall}\",\n",
    "      f\"RMSE: {eval_rmse}\",\n",
    "      f\"MAE: {eval_mae}\",\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   user_id  item_id               item_id_name      score  rank\n0        1       49                I.Q. (1994)        NaN   NaN\n1        1       69        Forrest Gump (1994)  47.925373   3.0\n2        1      221  Breaking the Waves (1996)        NaN   NaN\n3        1        5             Copycat (1995)        NaN   NaN\n4        1      139       Love Bug, The (1969)        NaN   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>item_id_name</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>49</td>\n      <td>I.Q. (1994)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>69</td>\n      <td>Forrest Gump (1994)</td>\n      <td>47.925373</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>221</td>\n      <td>Breaking the Waves (1996)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>139</td>\n      <td>Love Bug, The (1969)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Now let's look at the results for a specific user\n",
    "user_id = 1\n",
    "\n",
    "ground_truth = test[test[col_user]==user_id]\n",
    "prediction = topk_remove_seen[topk_remove_seen[col_user]==user_id].sort_values(by=col_score, ascending=False)[:TOP_K]\n",
    "test_user_movie_watched_prediction = (\n",
    "    pd.merge(ground_truth, prediction, on=[col_user, col_item], how='left')\n",
    "      .drop(columns=['rating'])\n",
    ")\n",
    "display(test_user_movie_watched_prediction.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that one of the movies from the test set was recovered by the model's top-k recommendations, however the others were not. Offline evaluations are difficult as they can only use what was seen previously in the test set and may not represent the user's actual preferences across the entire set of items. Adjustments to how the data is split, algorithm is used and hyper-parameters can improve the results here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "map",
       "data": 0.044028595315000515,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "map",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "ndcg",
       "data": 0.2443432424633656,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "ndcg",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "precision",
       "data": 0.2292682926829268,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "precision",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "recall",
       "data": 0.09436047878760673,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "recall",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "train_time",
       "data": 2.7274963530071545,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "train_time",
       "data": true,
       "display": false
      }
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/scrapbook.scrap.json+json": {
       "name": "test_time",
       "data": 4.676356565993046,
       "encoder": "json",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "name": "test_time",
       "data": true,
       "display": false
      }
     }
    }
   ],
   "source": [
    "# Record results with papermill for tests - ignore this cell\n",
    "sb.glue(\"map\", eval_map_k)\n",
    "sb.glue(\"ndcg\", eval_ndcg)\n",
    "sb.glue(\"precision\", eval_precision)\n",
    "sb.glue(\"recall\", eval_recall)\n",
    "sb.glue(\"train_time\", train_time.interval)\n",
    "sb.glue(\"test_time\", test_time.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.11 64-bit ('reco_base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "interpreter": {
   "hash": "98169291db0c76b5a29ac985497b93ea6e9ffb789b0c6c3e8a1bf753f6a69f0f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}